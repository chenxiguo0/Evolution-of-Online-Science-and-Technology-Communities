<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.54">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Project Report – Project-04: Evolution of Online Sci-Tech Communities</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Project-04: Evolution of Online Sci-Tech Communities</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./eda.html"> 
<span class="menu-text">Exploratory Data Analysis</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./nlp.html"> 
<span class="menu-text">Natural Language Processing</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./ml.html"> 
<span class="menu-text">Machine Learning</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./conclusion.html"> 
<span class="menu-text">Conclusion</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./report.html" aria-current="page"> 
<span class="menu-text">Report</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://gcx1372.georgetown.domains/chenxiguo_website/"> 
<span class="menu-text">Back to Portfolio</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#dataset" id="toc-dataset" class="nav-link" data-scroll-target="#dataset">Dataset</a></li>
  <li><a href="#method" id="toc-method" class="nav-link" data-scroll-target="#method">Method</a></li>
  <li><a href="#business-questions-and-technical-approaches" id="toc-business-questions-and-technical-approaches" class="nav-link" data-scroll-target="#business-questions-and-technical-approaches">10 Business Questions and technical approaches</a></li>
  <li><a href="#main-analysis" id="toc-main-analysis" class="nav-link" data-scroll-target="#main-analysis">Main Analysis</a>
  <ul class="collapse">
  <li><a href="#exploratory-data-analysis-eda" id="toc-exploratory-data-analysis-eda" class="nav-link" data-scroll-target="#exploratory-data-analysis-eda">Exploratory Data Analysis (EDA)</a></li>
  <li><a href="#natural-language-processing-nlp" id="toc-natural-language-processing-nlp" class="nav-link" data-scroll-target="#natural-language-processing-nlp">Natural Language Processing (NLP)</a></li>
  <li><a href="#machine-learning-ml" id="toc-machine-learning-ml" class="nav-link" data-scroll-target="#machine-learning-ml">Machine Learning (ML)</a></li>
  </ul></li>
  <li><a href="#key-recommendations" id="toc-key-recommendations" class="nav-link" data-scroll-target="#key-recommendations">Key Recommendations</a></li>
  <li><a href="#next-steps" id="toc-next-steps" class="nav-link" data-scroll-target="#next-steps">Next Steps</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Project Report</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Every day, millions of people gather on Reddit to make sense of rapid technological change. Some come to celebrate new AI breakthroughs, others to troubleshoot code, debate ethics, or simply share curiosity about the future. These conversations unfold across fragmented subreddits—each with its own tone, norms, and pace—yet they are all part of a broader ecosystem reacting in real time to the accelerating world of science and technology.</p>
<p>As AI tools reshape how people work, create, and communicate, online communities have become one of the most important places where public understanding takes shape. But despite the scale and influence of these spaces, we still know surprisingly little about how they evolve, what drives engagement, and how different groups organize around emerging technologies.</p>
<p>This leads to our core question:</p>
<p><strong>How do online science and technology communities on Reddit evolve, interact, and structure their discussions around AI and emerging technologies?</strong></p>
</section>
<section id="dataset" class="level2">
<h2 class="anchored" data-anchor-id="dataset">Dataset</h2>
<p>The dataset combines public Reddit comments and submissions across 100 subreddits, covering AI, programming, technology, and science. It contains over 12.5 million rows and spans from June 2023 to July 2024, providing a comprehensive view of user activity and discussions in these domains.</p>
</section>
<section id="method" class="level2">
<h2 class="anchored" data-anchor-id="method">Method</h2>
<p>We analyzed Reddit submissions and comments from science, technology, and AI communities using a combination of EDA, natural language processing (NLP), and machine learning techniques.</p>
<p>Data were processed with Apache Spark, aggregating posts and comments by subreddit and month to compute community activity, user retention, and attention concentration metrics.</p>
<p>NLP features included text cleaning, tokenization, stopword removal, TF-IDF or CountVectorizer encoding, topic modeling (LDA), sentiment analysis (VADER/TextBlob), and rule-based discussion type classification.</p>
<p>Machine learning involved Logistic Regression to predict comment quality using text and behavioral features (e.g., comment length, URL presence, posting time) and K-Means clustering (with PCA visualization) to identify distinct discussion communities.</p>
</section>
<section id="business-questions-and-technical-approaches" class="level2">
<h2 class="anchored" data-anchor-id="business-questions-and-technical-approaches">10 Business Questions and technical approaches</h2>
<p>See <a href="../BUSINESS_QUESTIONS.md">BUSINESS_QUESTIONS.md</a></p>
</section>
<section id="main-analysis" class="level2">
<h2 class="anchored" data-anchor-id="main-analysis">Main Analysis</h2>
<p>This section provides an integrated overview of insights from the three analytical components of the project: Exploratory Data Analysis (EDA), Natural Language Processing (NLP), and Machine Learning (ML). Each subsection summarizes the key discoveries and links to a dedicated analysis page that documents interactive visuals, methodological details, and complete result sets.</p>
<section id="exploratory-data-analysis-eda" class="level3">
<h3 class="anchored" data-anchor-id="exploratory-data-analysis-eda">Exploratory Data Analysis (EDA)</h3>
<p>The EDA characterizes structural patterns in community behavior across 40 AI and technology subreddits by examining activity dynamics, user retention, attention allocation, and cross-community participation. Across the 14 months, community activity displays a hybrid pattern: broad technology subreddits maintain high baseline volume, while AI-focused forums exhibit episodic spikes aligned with major releases and public announcements. This separation reflects different drivers of participation, general technological interest versus AI-specific event sensitivity.</p>
<p>User retention analysis further distinguishes communities by functional role. Mainstream AI subreddits (e.g., ChatGPT, MachineLearning) maintain stable return rates, indicating sustained month-to-month engagement. At the same time, niche or highly specialized communities show short, high-intensity retention bursts tied to topic relevance. These patterns indicate that community size and topic breadth shape long-term participation capacity.</p>
<p>Attention distribution also varies systematically across subreddit types. High-traffic communities exhibit an intense concentration of engagement with comment activity disproportionately captured by a small number of threads consistent with viral or news-driven dynamics. In contrast, technical and research-oriented subreddits (such as Machine Learning and Data Science) show lower attention inequality, supporting more evenly distributed, parallel discussions that align with expert-driven or problem-solving interactions.</p>
<p>Finally, user-overlap analysis reveals minimal cross-participation between AI and technology communities, even among subreddits addressing closely related topics. This indicates that Reddit’s AI ecosystem consists of distinct audience segments, each interacting primarily within its own topical domain rather than migrating across adjacent communities.</p>
<p>Together, these EDA results identify apparent structural differences in how AI and technology communities behave, including activity drivers, engagement stability, attention allocation, and user segmentation, providing the analytical foundation for the NLP and ML components of the project.</p>
<p>See full analysis in <a href="EDA_WEB.html">Exploratory Data Analysis</a></p>
</section>
<section id="natural-language-processing-nlp" class="level3">
<h3 class="anchored" data-anchor-id="natural-language-processing-nlp">Natural Language Processing (NLP)</h3>
<p>The NLP analysis examines the semantic structure, emotional tone, event responsiveness, and user-driven discussion patterns across 40 AI and technology-related subreddits. Topic modeling reveals a stable set of thematic structures centered on future-oriented technology, human–AI relations, practical learning and project development, programming workflows, and technology-driven business applications. After excluding a significant general conversational topic, the remaining themes remain remarkably consistent throughout the 14 months, indicating that community interests are persistent and not subject to substantial drift. These findings suggest that discussions in fast-growing AI and technology communities are shaped by enduring concerns about technological impact, career development, and practical implementation rather than short-lived trends.</p>
<p>Sentiment analysis using VADER further demonstrates that the emotional tone across all major communities is predominantly neutral to mildly positive. Average sentiment scores remain stable over time, with only modest fluctuations in AI-focused subreddits around major product announcements or regulatory milestones such as the Gemini release or the EU AI Act. These shifts, however, are short-lived and do not meaningfully alter the long-term emotional landscape. Programming, science, and broader technology communities show even less sensitivity to external events, reinforcing the conclusion that discourse in these communities is informational and measured rather than reactive or volatile.</p>
<p>To understand how users contribute to different forms of discourse, discussions were categorized into technical, ethical, societal, and general content. Technical discussions emphasize model architectures, data workflows, and computational methods; ethical discussions focus on fairness, regulation, and governance; societal discussions address employment, corporate influence, and broader social implications; and general discussions reflect meta-talk, moderation, or uncategorized exchanges. These distinctions reveal parallel layers of conversation, each shaped by distinct user groups with different informational needs and priorities.</p>
<p>Overall, the NLP analysis shows that Reddit’s AI and technology discussions form a stable, multidimensional discourse environment. Community conversations are thematically coherent, emotionally steady, and only marginally influenced by external technological or policy events. Users contribute across diverse topical layers—from technical implementation to societal impact—indicating a mature and sustained public engagement with emerging technologies.</p>
<p>See full analysis in <a href="NLP_WEB.html">Natural Language Processing</a></p>
</section>
<section id="machine-learning-ml" class="level3">
<h3 class="anchored" data-anchor-id="machine-learning-ml">Machine Learning (ML)</h3>
<p>The ML analysis explores the predictability of comment quality and the identification of distinct discussion communities within Reddit’s AI and technology subreddits. Using a combination of text features and behavioral metrics, we applied classification and clustering models to uncover patterns in content quality and thematic segmentation.</p>
<p>To examine comment quality, we trained a Logistic Regression model using text features generated via Tokenizer → StopWordsRemover → HashingTF → IDF, along with behavioral features such as comment length, presence of URLs, and posting hour/day. The model is partially successful: it achieves high recall for general high-quality comments (≈71%) but low precision (≈22%), while highly popular comments and low-quality comments show moderate recall and very low precision. These results indicate that the model is suitable for flagging candidate comments for manual review rather than for fully automated moderation, and that further improvement would require richer semantic representations and additional features.</p>
<p>For community detection, we combined submission titles and selftext to generate TF-IDF features, then applied K-Means clustering (K=13) with PCA visualization. The analysis revealed that most submissions (≈98%) cluster into everyday, general discussion groups, while a small portion (≈2%) forms tightly focused technical/programming clusters. This demonstrates that language-based clustering can separate broad conversational communities from specialized technical discussions, providing a foundation for downstream analyses such as sentiment tracking, engagement prediction, and content segmentation.</p>
<p>See full analysis in <a href="ML_WEB.html">Machine Learning</a></p>
</section>
</section>
<section id="key-recommendations" class="level2">
<h2 class="anchored" data-anchor-id="key-recommendations">Key Recommendations</h2>
<p>Our findings suggest several strategic recommendations for engaging with Reddit’s science and technology communities:</p>
<ol type="1">
<li><strong>Align with Key Events:</strong> Capitalize on the event-driven nature of AI subreddits by timing announcements and content to coincide with major industry milestones.</li>
<li><strong>Tailor Content to the Audience:</strong> Differentiate between technical and general-interest communities. Provide in-depth content for niche forums and high-level, concise narratives for broader ones.</li>
<li><strong>Focus on High-Impact Threads:</strong> In large subreddits, strategically engage in viral or high-visibility posts to maximize influence and shape community sentiment.</li>
<li><strong>Leverage the Constructive Environment:</strong> The stable, neutral-to-positive sentiment provides a safe space for organizations to contribute expert insights and educational content.</li>
<li><strong>Use ML for Triage, Not Automation:</strong> While our predictive models have high recall, their precision is limited. Use them to flag content for human review rather than for fully automated moderation.</li>
<li><strong>Segment Engagement Strategies:</strong> Recognize that most discussions are casual. Develop broad, conversational content for the majority, while reserving targeted, technical material for specialized subgroups to improve engagement efficiency.</li>
</ol>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next Steps</h2>
<p>Future work could extend this analysis in several promising directions:</p>
<ul>
<li><strong>Advanced Modeling:</strong> Improve predictive accuracy by using contextual language embeddings (e.g., BERT), richer metadata, and more sophisticated classifiers like gradient boosting or transformers.</li>
<li><strong>Nuanced Community Detection:</strong> Employ hierarchical or density-based clustering to uncover more subtle community structures and integrate these findings into forecasting models.</li>
<li><strong>Longitudinal and Causal Analysis:</strong> Extend the analysis over a longer timeframe to track multi-year evolution and integrate external datasets (e.g., news sentiment, policy timelines) to establish causal links between real-world events and online discourse.</li>
<li><strong>Forecasting Pipelines:</strong> Develop a full forecasting pipeline to predict subreddit-level sentiment and activity, enabling proactive communication and engagement strategies.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>DSAN 6000 Big Data Analytics Project</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>Made with <a href="https://quarto.org/">Quarto</a></p>
</div>
  </div>
</footer>




</body></html>