[
  {
    "objectID": "ML_WEB.html",
    "href": "ML_WEB.html",
    "title": "Machine Learning",
    "section": "",
    "text": "In this milestone, we harness the power of Apache Spark’s MLlib to explore and analyze Reddit discussions in science, technology, and AI communities. By applying a suite of machine learning techniques, we aim to uncover patterns in user behavior and comment content, and use these insights to tackle two key business questions. Through classification and regression models, we translate raw textual and behavioral data into actionable predictions, providing a deeper understanding of comment quality and the structure of discussion communities across technology-related subreddits."
  },
  {
    "objectID": "ML_WEB.html#overview",
    "href": "ML_WEB.html#overview",
    "title": "Machine Learning",
    "section": "",
    "text": "In this milestone, we harness the power of Apache Spark’s MLlib to explore and analyze Reddit discussions in science, technology, and AI communities. By applying a suite of machine learning techniques, we aim to uncover patterns in user behavior and comment content, and use these insights to tackle two key business questions. Through classification and regression models, we translate raw textual and behavioral data into actionable predictions, providing a deeper understanding of comment quality and the structure of discussion communities across technology-related subreddits."
  },
  {
    "objectID": "ML_WEB.html#business-question-9-can-the-quality-of-reddit-comments-in-science-technology-and-ai-subreddits-be-predicted-from-comment-content-and-basic-behavioral-features",
    "href": "ML_WEB.html#business-question-9-can-the-quality-of-reddit-comments-in-science-technology-and-ai-subreddits-be-predicted-from-comment-content-and-basic-behavioral-features",
    "title": "Machine Learning",
    "section": "Business Question 9: Can the Quality of Reddit Comments in Science, Technology, and AI Subreddits Be Predicted from comment content and basic behavioral features?",
    "text": "Business Question 9: Can the Quality of Reddit Comments in Science, Technology, and AI Subreddits Be Predicted from comment content and basic behavioral features?\n\nExperiment Introduction:\nThe Reddit score is calculated using the platform’s voting system and is defined as:\nscore = upvotes − downvotes\nThis value reflects community evaluation of how useful or high-quality a comment is.\nTo explore how well we can predict comment quality under different definitions, we designed three classification experiments:\n\nExperiment 1 – Predicting general high-quality comments\n\nPositive class: score ≥ 6\n\nRepresents comments with moderate positive engagement.\n\nExperiment 2 – Predicting highly popular high-quality comments\n\nPositive class: score ≥ 20\n\nTargets comments that achieved strong community resonance.\n\nExperiment 3 – Predicting low-quality comments\n\nPositive class: score &lt; 0\n\nA reverse-classification setup focusing on comments evaluated negatively by the community.\n\n\nClass weighting applied to address imbalance (weightCol used in LogisticRegression).\nTrain/test splits performed in code (80/20).\nAcross all three experiments, we trained Logistic Regression models using both TF-IDF text features and behavioral features such as comment length, URL presence, posting hour, and day of week.\nModel performance was evaluated using standard classification metrics including Accuracy, Precision, Recall, F1-score, and AUC.\n\n\nModel performance on Experiment 1\n\n\n\nMetric\nAccuracy\nPrecision\nRecall\nF1-score\nAUC\n\n\n\n\nValue\n0.5047\n0.2227\n0.7064\n0.3386\n0.6257\n\n\n\n\n  \n\nOverall, the model exhibits a clear bias in identifying high-quality comments. On one hand, it successfully detects 318,706 high-quality comments (true positives), demonstrating strong recall; on the other hand, it misclassifies 1,112,372 low-quality comments as high-quality (false positives), indicating substantial difficulty in distinguishing positive from negative samples. This “high recall, low precision” pattern means the model is effective at capturing potentially valuable content but generates a large number of false alarms, making it unsuitable for fully automated applications requiring high precision.\nIn terms of overall performance, the ROC curve shows AUC = 0.626, only slightly better than random guessing, indicating limited discriminative ability. Further inspection of the Precision–Recall curve reveals that, due to the low precision, simply adjusting thresholds is unlikely to significantly improve precision, reflecting a performance ceiling with the current feature representation. The main reason is that the current HashingTF text representation fails to effectively capture semantic information, making it difficult to distinguish high-value comments from regular ones.\n\n\nModel performance on Experiment 2\n\n\n\nMetric\nAccuracy\nPrecision\nRecall\nF1-score\nAUC\n\n\n\n\nLogisticRegression\n0.575\n0.069\n0.611\n0.125\n0.636\n\n\n\n\n  \n\nThe model identifies a portion of high-quality comments (76,072 true positives) but misclassifies a substantial number of low-quality comments as high-quality (1,020,158 false positives). In the original dataset, high-quality comments constitute only a small fraction of the total samples, reflecting a significant class imbalance. Although we applied class weighting in Logistic Regression to partially mitigate this imbalance, the model still exhibits extremely low precision (0.069) despite moderate recall (0.611).\nThe ROC curve shows AUC = 0.636, indicating that the model has modest discriminative ability — it performs better than random but is far from optimal. The Precision–Recall (PR) curve further highlights the issue: while recall is reasonable, precision remains extremely low, and adjusting the classification threshold is unlikely to improve it substantially. This demonstrates that the model tends to predict a large number of samples as positive (high-quality), resulting in many false positives.\n\n\nModel performance on Experiment 3\n\n\n\nAccuracy\nPrecision\nRecall\nF1-score\nAUC\n\n\n\n\n0.605\n0.067\n0.634\n0.121\n0.666\n\n\n\n\n  \n\nThe model identifies a portion of low-quality comments (68,049 true positives) but misclassifies a substantial number of high-quality comments as low-quality (953,913 false positives). In the original dataset, low-quality comments constitute only a small fraction of the total samples, reflecting a significant class imbalance. Although we applied class weighting in Logistic Regression to partially mitigate this imbalance, the model still exhibits extremely low precision (0.067) despite moderate recall (0.634).\nThe ROC curve shows AUC = 0.666, indicating that the model has modest discriminative ability — it performs better than random but is far from optimal. The Precision–Recall (PR) curve further highlights the issue: while recall is reasonable, precision remains extremely low, and adjusting the classification threshold is unlikely to improve it substantially. This demonstrates that the model tends to predict a large number of samples as positive (low-quality), resulting in many false positives.\nThis “high recall, very low precision” behavior suggests that the model may be useful for flagging potential low-quality comments for further review but is not suitable for fully automated high-precision applications. Compared with Experiment 1 (general high-quality comments), the precision is even lower, indicating that predicting low-quality comments is particularly challenging due to their rarity and the limitations of the current text and behavioral features.\n\n\nAnswer of Business Question 9\nSummary and Comparison of Experiments:\nAcross the three experiments, Logistic Regression models showed the following patterns:\n\nExperiment 1 (general high-quality comments): High recall (≈71%) but low precision (≈22%), indicating the model can identify most high-quality comments but produces many false positives.\n\nExperiment 2 (highly popular high-quality comments): Even lower precision (≈7%) with moderate recall (≈63%), reflecting the difficulty of predicting rare highly popular comments despite applying class weighting.\n\nExperiment 3 (low-quality comments): Low precision (≈7%) with moderate recall (≈61%), showing that identifying low-quality comments is also challenging but feasible for flagging purposes.\n\nConclusion:\nLogistic Regression can partially predict comment quality using text and behavioral features. The models are useful for flagging candidate comments (high recall), but due to low precision, they are not suitable for fully automated decisions. Predicting extreme categories (highly popular or low-quality comments) is more difficult due to class imbalance and feature limitations.\nTherefore, key directions for improving model performance are:\n\nUse stronger semantic embeddings (e.g., BERT, Sentence-BERT) to better capture contextual and semantic information in comments.\nApply more powerful classifiers (e.g., Gradient Boosting, XGBoost, LightGBM) and incorporate richer metadata.\nFurther optimize threshold strategies and feature engineering based on task requirements."
  },
  {
    "objectID": "ML_WEB.html#business-question-10-can-distinct-discussion-communities-be-identified-within-technology-related-subreddits-based-on-patterns-of-language-use",
    "href": "ML_WEB.html#business-question-10-can-distinct-discussion-communities-be-identified-within-technology-related-subreddits-based-on-patterns-of-language-use",
    "title": "Machine Learning",
    "section": "Business Question 10: Can distinct discussion communities be identified within technology-related subreddits based on patterns of language use?",
    "text": "Business Question 10: Can distinct discussion communities be identified within technology-related subreddits based on patterns of language use?\n\nIntroduction\nIn this analysis, we aim to explore whether technology-related subreddits exhibit distinct discussion communities that can be characterized by their language patterns. By examining the textual content of subreddit submissions, we investigate the extent to which subreddits cluster together based on shared terminology, phrasing, and communication styles. Identifying these communities can provide insights into topic specialization, user engagement, and the structure of discourse across different forums. This understanding can also inform strategies for content moderation, recommendation systems, and targeted community engagement.\nWe randomly selected 50,000 subreddit submissions and applied K-Means clustering to their TF-IDF features. The goal was to identify groups of subreddits that share similar textual content and language use. The elbow method was used to determine the optimal number of clusters (K).\n\nCluster artifacts and model saved in code/ml/models/kmeans_k13.\nCluster analysis summary: data/csv/ML2_cluster_analysis.csv.\nElbow chart for K selection: data/plots/ML2_elbow_method.png.\n\n\n\nAnalysis：\n\nAfter applying the elbow method to evaluate the optimal number of clusters, and balancing within-cluster cohesion against between-cluster separation, we ultimately selected 13 clusters. This choice preserves thematic consistency within each cluster while ensuring sufficient distinction between clusters, thereby capturing meaningful differences in language use across technology-related subreddits.\nThis is the cluster visualization：\nThis cluster visualization shows that some clusters are fairly well-separated, while others are tightly overlapping. \nCluster Sizes and Distribution\nCluster sizes vary significantly, from small technical or code-specific clusters (size 6–185) to very large community discussion clusters (size 4,989–43,558).\nLargest clusters:\nCluster 10 (43,558) – AI community high-frequency discussions, including ChatGPT-related topics.\nCluster 8 (4,989) – Natural-language conversational discussions, reflecting informal user interactions.\nMedium clusters: Clusters 3, 6, and 11 (185–511) capture AI-related code/project discussions, AI comment interactions, and Python tutorials.\nSmall clusters: Clusters 0–5, 7, 9, 12 (6–301) are focused on specific programming tasks, code snippets, game logic, front-end layout, or grid/table operations.\n\n\n\n\n\n\n\n\n\nCluster ID\nSize\nTop Terms\nCategory Tendency\n\n\n\n\n0\n14\npaused, playing, def, import, printstrfplaypause, const, new, return, else\nAudio/video player related code snippets / scripting functionality\n\n\n1\n17\nreturn, x, resize, div, px, int, y, tilesize, public\nFront-end web layout / GUI related code\n\n\n2\n43\nreturn, import, def, guess, code, data, px, value, div\nPython programming basics / data processing / small program logic\n\n\n3\n185\nai, xb, code, import, new, data, x, return, use\nAI-related code or project implementation / algorithm development\n\n\n4\n13\nxb, false, player, temparray, return, gamepass, manufacturer, imgnull, true\nGame development or player logic / small program functionality\n\n\n5\n6\nreturn, import, public, int, new, cell, def, class, grid\nGrid or table processing / object-oriented basic code\n\n\n6\n511\nai, like, im, data, use, time, get, code, new\nAI community comments / user interaction related text\n\n\n7\n99\nimport, return, def, div, left, right, else, data, code\nFront-end layout and function logic / web page scripting\n\n\n8\n4989\nim, like, time, ive, know, get, work, ai, dont\nCommunity natural-language discussions / user comments / social interaction\n\n\n9\n162\ncode, import, xb, im, return, new, file, like, def\nProgramming discussion / file operations / small scripts\n\n\n10\n43558\nremoved, im, ai, like, chatgpt, gpt, new, use, get\nAI community high-frequency discussions / ChatGPT-related topics\n\n\n11\n301\ncode, im, def, xb, import, like, return, python, x\nProgramming tutorials / Python code examples / scripts\n\n\n12\n102\ntime, like, ai, xb, people, one, get, new, first\nAI community comments / user time and opinion expression\n\n\n\nCluster Content Summary\n\n\n\n\n\n\n\n\n\nCategory\nCluster IDs\nPercentage\nDescription\n\n\n\n\nNatural-Language / General Discussion\n10, 8, 6, 12\n98%\nLarge-scale conversational content, general discussions about AI, user opinions, and everyday language.\n\n\nProgramming / Technical Content\n0, 1, 2, 3, 5, 7, 9, 11\n2%\nCode snippets, debugging, Python scripts, front-end layouts, data-processing code, and AI project implementation.\n\n\n\nBased on K-Means clustering of 50,000 randomly selected subreddit submissions, we categorized 13 clusters into two main content domains: Natural-Language / General Discussion and Programming / Technical Content.\nNatural-Language / General Discussion (Clusters 6, 8, 10, 12 – 98% of submissions)\nCluster 10 (43,558 submissions): High-frequency AI discussions, including ChatGPT, AI concepts, and moderation-related content (‘removed’). Represents the largest portion of general AI conversations.\nCluster 8 (4,989 submissions): Conversational discussions with informal language (‘im’, ‘like’, ‘time’), reflecting community interactions and casual exchanges.\nCluster 6 (511 submissions): AI-related comments with a mix of technical terms and user interactions (‘ai’, ‘code’, ‘use’, ‘time’), bridging casual discussion and technical engagement.\nCluster 12 (102 submissions): Smaller cluster capturing user opinions, timing, and interaction patterns in AI-related discussions.\nInsight: These clusters dominate Reddit AI conversations, reflecting large-scale user engagement, opinion sharing, and general discussion.\nProgramming / Technical Content (Clusters 0, 1, 2, 3, 5, 7, 9, 11 – 2% of submissions)\nClusters 0, 1, 2, 5, 7, 9, 11: Focus on coding examples, debugging, front-end layouts, and small programming projects. Examples include Python basics, grid/table processing, and front-end scripts.\nCluster 3 (185 submissions): AI-related project implementation and algorithm development, combining technical code with problem-solving content.\nInsight: These clusters are smaller in size but highly specialized, capturing programming-focused discussions and technical knowledge sharing.\n\n\nOverall Interpretation\nThe clustering effectively separates high-volume conversational discussions from smaller, specialized technical content.\nLarge clusters (Natural-Language) reflect broad engagement and informal community interactions.\nSmall clusters (Technical Content) capture targeted programming topics and code-oriented tasks.\nThese cluster distinctions provide a foundation for feature engineering in predictive models, sentiment analysis, or engagement forecasting, allowing models to treat conversational and technical clusters differently."
  },
  {
    "objectID": "ML_WEB.html#summary",
    "href": "ML_WEB.html#summary",
    "title": "Machine Learning",
    "section": "Summary",
    "text": "Summary\n\nCan the Quality of Reddit Comments in Science, Technology, and AI Subreddits Be Predicted from comment content and basic behavioral features?\n\nPartially predictable: Logistic Regression using text and behavioral features can capture potential high- and low-quality comments, but precision is low.\nPerformance overview:\nGeneral high-quality comments: high recall (≈71%), low precision (≈22%)\nHighly popular high-quality comments: moderate recall (≈63%), very low precision (≈7%)\nLow-quality comments: moderate recall (≈61%), low precision (≈7%)\nConclusion: Models are suitable for flagging candidate comments for manual review but not for fully automated decisions. Improving performance requires stronger semantic representations and richer features.\n\nCan distinct discussion communities be identified within technology-related subreddits based on patterns of language use?\n\nIdentifiable: K-Means clustering (K=13) successfully separated submissions into natural-language/general discussion (98%) and programming/technical content (2%).\nConclusion: Clustering effectively distinguishes broad community interactions from specialized technical topics, providing a foundation for predictive modeling, sentiment analysis, and engagement forecasting."
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "This section presents a comprehensive exploratory data analysis (EDA) of user activity across 46 major AI and technology-focused subreddits from June 2023 to July 2024. By processing a large-scale dataset of over 12 million comments and 800,000 submissions with Spark and Python, we investigate four key business questions. Our analysis uncovers temporal activity patterns, quantifies user engagement and retention, measures attention inequality in discussions, and maps the landscape of cross-community user overlap. These findings provide a foundational understanding of the behavioral dynamics shaping the Reddit AI and technology ecosystem."
  },
  {
    "objectID": "eda.html#overview",
    "href": "eda.html#overview",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "This section presents a comprehensive exploratory data analysis (EDA) of user activity across 46 major AI and technology-focused subreddits from June 2023 to July 2024. By processing a large-scale dataset of over 12 million comments and 800,000 submissions with Spark and Python, we investigate four key business questions. Our analysis uncovers temporal activity patterns, quantifies user engagement and retention, measures attention inequality in discussions, and maps the landscape of cross-community user overlap. These findings provide a foundational understanding of the behavioral dynamics shaping the Reddit AI and technology ecosystem."
  },
  {
    "objectID": "eda.html#data-overview",
    "href": "eda.html#data-overview",
    "title": "Exploratory Data Analysis",
    "section": "Data Overview",
    "text": "Data Overview\n\nDataset Summary\nThis project analyzes a large-scale Reddit dataset covering user activity from June 2023 to July 2024 across 46 unique subreddits, enabling a comprehensive examination of engagement patterns and community dynamics.\nThe dataset’s overall scope is detailed in Table 1. It comprises over 12.5 million comments and 831,000 submissions, providing a rich foundation for analyzing user-generated content and discussion patterns.\nDataset Summary by Data Type\n\n\n\n\n\n\n\n\n\n\nData Type\nTotal Rows\nSize (GB)\nDate Range Start\nDate Range End\n\n\n\n\ncomments\n12,561,291\n12.56\n2023-06-01\n2024-07-31\n\n\nsubmissions\n831,021\n0.83\n2023-06-01\n2024-07-31\n\n\n\nAmong the 46 communities, activity is highly concentrated in a few key subreddits. The top five, measured by the total number of comments and submissions, are:\n\ntechnology — 3,265,248 total rows\n\nChatGPT — 1,894,755 total rows\n\nscience — 1,051,336 total rows\n\ncscareerquestions — 974,990 total rows\n\nFuturology — 914,347 total rows\n\nTo facilitate temporal analysis, this raw data was aggregated into monthly activity counts. Table 2 provides a sample of this structured data, which is used to explore activity trends in Business Question 1.\nSample of Monthly Activity Data\n\n\n\n\n\n\n\n\n\n\nsubreddit\nmonth\nposts\ncomments\ntotal_activity\n\n\n\n\nArtificialInteligence\n2023-06-01\n1900\n11962\n13862\n\n\nArtificialInteligence\n2023-07-01\n1829\n12078\n13907\n\n\nArtificialInteligence\n2023-08-01\n1759\n9922\n11681\n\n\nChatGPT\n2023-06-01\n11357\n139633\n150990\n\n\nChatGPT\n2023-07-01\n10597\n142224\n152821\n\n\nChatGPT\n2023-08-01\n10431\n131996\n142427"
  },
  {
    "objectID": "eda.html#business-question-1-your-eda-question",
    "href": "eda.html#business-question-1-your-eda-question",
    "title": "Exploratory Data Analysis",
    "section": "Business Question 1: [Your EDA Question]",
    "text": "Business Question 1: [Your EDA Question]\nQuestion: [Full question text]\n\nAnalysis Approach\n[Brief description of methodology]\n\n\nFindings\n[Placeholder for visualization]\nKey Insights:\n\n[Insight 1]\n[Insight 2]\n[Insight 3]"
  },
  {
    "objectID": "eda.html#business-question-2-your-eda-question",
    "href": "eda.html#business-question-2-your-eda-question",
    "title": "Exploratory Data Analysis",
    "section": "Business Question 2: [Your EDA Question]",
    "text": "Business Question 2: [Your EDA Question]\nQuestion: [Full question text]\n\nAnalysis Approach\n[Brief description of methodology]\n\n\nFindings\n[Placeholder for visualization]\nKey Insights:\n\n[Insight 1]\n[Insight 2]\n[Insight 3]"
  },
  {
    "objectID": "eda.html#temporal-analysis",
    "href": "eda.html#temporal-analysis",
    "title": "Exploratory Data Analysis",
    "section": "Temporal Analysis",
    "text": "Temporal Analysis\n\nPosting Patterns Over Time\n[Description of temporal patterns discovered]\n\n\nPeak Activity Analysis\nHourly Patterns:\n\nPeak hours: [Hours]\nLowest activity: [Hours]\n\nWeekly Patterns:\n\nMost active days: [Days]\nLeast active days: [Days]"
  },
  {
    "objectID": "eda.html#summary",
    "href": "eda.html#summary",
    "title": "Exploratory Data Analysis",
    "section": "Summary",
    "text": "Summary\nThis exploratory analysis reveals several key dynamics of Reddit’s AI and technology ecosystem:\n\nCommunity Activity is Event-Driven: Monthly activity in specialized subreddits like ChatGPT spikes in response to major industry events, while broader forums like technology maintain high, consistent engagement.\nRetention Varies by Community Type: Niche communities experience volatile but intense user retention, whereas larger, mainstream subreddits demonstrate more stable and durable long-term engagement.\nAttention is Highly Concentrated in Large Forums: General-interest tech subreddits exhibit a “winner-take-most” pattern where a few viral posts dominate discussion. In contrast, technical communities foster a more equitable distribution of attention.\nUser Communities are Highly Siloed: There is minimal user overlap between different AI and tech subreddits, indicating that these online spaces operate as distinct communities with specialized audiences rather than an interconnected network."
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "Conclusion and Recommendations",
    "section": "",
    "text": "This project analyzed the evolution of science and technology communities on Reddit to understand how they shape public sentiment and discourse around AI and emerging technologies. By processing over 13 million Reddit submissions and comments from June 2023 to July 2024 using Apache Spark, we conducted a comprehensive analysis spanning Exploratory Data Analysis (EDA), Natural Language Processing (NLP), and Machine Learning (ML). Our findings reveal that community activity is highly event-driven, discussions are predominantly neutral-to-positive but can be influenced by major tech announcements, and distinct user communities exist with varying levels of engagement and topic concentration. The machine learning models we developed provide a framework for identifying high-quality content and segmenting discussions, offering valuable tools for community managers, marketers, and researchers aiming to understand and engage with these dynamic online ecosystems."
  },
  {
    "objectID": "conclusion.html#executive-summary",
    "href": "conclusion.html#executive-summary",
    "title": "Conclusion and Recommendations",
    "section": "",
    "text": "This project analyzed the evolution of science and technology communities on Reddit to understand how they shape public sentiment and discourse around AI and emerging technologies. By processing over 13 million Reddit submissions and comments from June 2023 to July 2024 using Apache Spark, we conducted a comprehensive analysis spanning Exploratory Data Analysis (EDA), Natural Language Processing (NLP), and Machine Learning (ML). Our findings reveal that community activity is highly event-driven, discussions are predominantly neutral-to-positive but can be influenced by major tech announcements, and distinct user communities exist with varying levels of engagement and topic concentration. The machine learning models we developed provide a framework for identifying high-quality content and segmenting discussions, offering valuable tools for community managers, marketers, and researchers aiming to understand and engage with these dynamic online ecosystems."
  },
  {
    "objectID": "conclusion.html#answers-to-all-10-business-questions",
    "href": "conclusion.html#answers-to-all-10-business-questions",
    "title": "Conclusion and Recommendations",
    "section": "Answers to All 10 Business Questions",
    "text": "Answers to All 10 Business Questions\n\nEDA Questions\nHow has community activity evolved across science, technology, and AI subreddits over time?:\nCommunity activity, measured by posts and comments, shows significant temporal fluctuations. Subreddits like r/ChatGPT, r/technology, and r/Futurology exhibit notable spikes in engagement that correlate with major industry events, such as new AI model launches in early and mid-2024.\nWhich technology-related subreddits demonstrate the strongest user engagement and retention over time?:\nEstablished communities like r/MachineLearning and r/ChatGPT maintain higher and more stable user retention ratios, indicating strong community “stickiness.” In contrast, smaller or more niche subreddits display more volatile engagement, with a higher proportion of one-time contributors.\nHow concentrated is attention within technology-related discussions?:\nAttention is highly concentrated in large, general-interest subreddits like r/technology (Gini coefficient &gt; 0.9), where a few viral posts dominate discussions. Specialized communities such as r/datascience show more egalitarian patterns, with engagement spread more evenly across posts.\nDo science, technology, and AI subreddits share overlapping user communities?:\nYes, there is strong user overlap among core AI-focused subreddits (r/ChatGPT, r/OpenAI, r/ArtificialInteligence), indicating a shared, highly engaged user base. General tech forums like r/technology act as bridges, connecting the AI-centric groups with a broader audience.\n\n\nNLP Questions\nWhat are the dominant topics and trends within fast-growing technology-related subreddits?:\nUsing LDA topic modeling, we identified ten dominant topics. The most prevalent were informal conversations (22.4%), discussions on human-AI relations and future technologies (13.6%), and career/learning-focused content (13%). These topic distributions remained remarkably stable over the one-year period.\nWhat are the baseline emotional patterns of discussions about AI and emerging technologies?:\nThe overwhelming majority of discussions are emotionally neutral. However, there is a consistent positive skew, with more positive comments than negative ones across nearly all subreddits. The average sentiment remains in the neutral-to-mildly-positive range, suggesting a generally constructive atmosphere.\nHow do external technological or policy events disrupt or reshape existing discussion patterns?:\nWhile overall sentiment is stable, the AI/ML-focused subreddits show noticeable, albeit temporary, increases in positive sentiment following major events like the Gemini launch and the passing of the EU AI Act. Topic trends, however, remain largely undisrupted, indicating that the core discussion themes are resilient to short-term events.\nHow do users shape topic emphasis and sentiment dynamics across science, technology, and AI subreddits?:\nThrough rule-based classification, we identified distinct vocabularies for different discussion types. “Ethical” discussions feature words like regulation and bias, “societal” discussions focus on jobs and impact, and “technical” discussions are dominated by terms like model and data. This shows that users adopt specific language to frame their conversations, shaping the thematic focus of each category.\n\n\nML Questions\nCan the Quality of Reddit comments be predicted?:\nPartially yes: A Logistic Regression model using text and behavioral features can capture high- and low-quality comments, but precision is low (high recall, low precision), making it suitable for flagging content for human review rather than fully automated decisions.\nCan distinct discussion communities be identified based on language use?:\nYes: K-Means clustering (K=13) separated most discussions into everyday/conversational content (≈98%) and a small set of technical/programming content (≈2%), indicating that communities can be distinguished by language use, providing a basis for analysis, predictive modeling, and community insights."
  },
  {
    "objectID": "conclusion.html#major-findings",
    "href": "conclusion.html#major-findings",
    "title": "Conclusion and Recommendations",
    "section": "Major Findings",
    "text": "Major Findings\n\nKey Insight 1: Community Engagement is Event-Driven but Emotionally Stable\nOur EDA and NLP analyses revealed that while user activity (posts, comments) surges in response to external events like AI product launches, the overall sentiment of the communities remains remarkably stable and neutral-to-positive. Business Impact: This suggests that stakeholders should not overreact to short-term activity spikes. While these events draw attention, they do not fundamentally alter the underlying positive and constructive tone of the communities. Marketing and engagement strategies can be planned around major tech milestones to maximize reach, without needing to constantly adapt to perceived emotional volatility.\n\n\nKey Insight 2: A Core, Interconnected AI Community Drives the Conversation\nUser overlap analysis (Jaccard similarity) demonstrated that a handful of core AI subreddits (r/ChatGPT, r/OpenAI, r/ArtificialInteligence) share a significant and active user base. These communities function as the central hub of the AI discourse on Reddit. Business Impact: For organizations looking to influence or understand the AI conversation, focusing engagement efforts on this core set of interconnected communities is far more efficient than a scattered approach. These are the places where ideas are born and disseminated to the wider tech ecosystem.\n\n\nKey Insight 3: Most Conversations Are Casual, with a Few Tight-Knit Tech Corners:\nOur research reveals that the vast majority of submissions (≈98%) cluster into everyday, natural-language discussions, while only a small portion (≈2%) forms specialized technical or programming clusters. Business Impact: This indicates that most engagement occurs around broad, conversational topics rather than highly technical content. Stakeholders aiming to foster participation, surface insights, or promote initiatives should focus on these larger, general-interest discussions while recognizing that technical content, though smaller, represents a highly engaged niche audience that may require targeted strategies."
  },
  {
    "objectID": "conclusion.html#addressing-the-high-level-problem",
    "href": "conclusion.html#addressing-the-high-level-problem",
    "title": "Conclusion and Recommendations",
    "section": "Addressing the High-Level Problem",
    "text": "Addressing the High-Level Problem\nOriginal Problem Statement: How do online science and technology communities on Reddit evolve and shape public understanding and sentiment toward AI and emerging technologies?\nHow Our Analysis Addresses It: Our comprehensive analysis provides a multi-faceted answer to this question. We demonstrated that these communities evolve in response to real-world events, with activity levels serving as a barometer for public interest (BQ1, BQ7). We quantified their structure, revealing that engagement is not uniform; some communities are “sticky” and retain users (BQ2), while others have highly concentrated “viral” discussions (BQ3). A core group of interconnected subreddits acts as the central nervous system for AI discourse (BQ4).\nFurthermore, we mapped the substance of these conversations. We found that the discourse is thematically diverse, covering technical, ethical, and societal dimensions (BQ5, BQ8), and maintains a surprisingly stable, neutral-to-positive emotional baseline (BQ6). Finally, our ML models provide a forward-looking capability, offering methods to identify high-quality content (BQ9) and segment the audience based on language (BQ10), which are crucial steps in actively shaping public understanding. Together, these findings paint a detailed picture of not just how these communities evolve, but what drives their evolution and shapes their internal dynamics."
  },
  {
    "objectID": "conclusion.html#business-recommendations",
    "href": "conclusion.html#business-recommendations",
    "title": "Conclusion and Recommendations",
    "section": "Business Recommendations",
    "text": "Business Recommendations\n\nRecommendation 1: Target Core AI Subreddits for High-Impact Engagement\nBased on: EDA findings on user overlap (BQ4) and attention concentration (BQ3). Action: Focus community management, marketing, and research efforts on the highly interconnected cluster of r/ChatGPT, r/OpenAI, and r/ArtificialInteligence. Use the “viral” nature of these forums to launch announcements or seed discussions. Expected Impact: More efficient use of resources, leading to higher visibility and greater influence on the central AI conversation.\n\n\nRecommendation 2: Use Sentiment Analysis as a Barometer, Not an Alarm\nBased on: NLP findings on sentiment stability and event-driven fluctuations (BQ6, BQ7). Action: Implement a monitoring dashboard that tracks sentiment in key subreddits. Use it to gauge the reception of new products or news, but avoid making drastic strategy changes based on short-term emotional shifts. The baseline is positive; focus on long-term trends. Expected Impact: More resilient and data-informed communication strategies that are proactive rather than reactive, fostering trust within the community.\n\n\nRecommendation 3: Differentiate Content Strategies for Casual vs. Technical Discussions\nBased on: ML findings on discussion clustering, showing that most conversations (≈98%) are casual, natural-language interactions, while a small fraction (≈2%) are specialized technical/programming clusters (BQ10). Action: Tailor content and engagement strategies according to the type of discussion. Use broad, conversational content to foster general community interaction and awareness, while producing targeted, technical posts for niche programming or AI-focused subgroups. Consider leveraging clustering insights for personalized recommendations, topic segmentation, or feature engineering in predictive models. Expected Impact: Improved community engagement and efficiency by addressing both large-scale casual discussions and specialized technical audiences with appropriate messaging and interventions."
  },
  {
    "objectID": "conclusion.html#limitations-and-future-work",
    "href": "conclusion.html#limitations-and-future-work",
    "title": "Conclusion and Recommendations",
    "section": "Limitations and Future Work",
    "text": "Limitations and Future Work\n\nLimitations\n\nSentiment Analysis Nuance: VADER is a lexicon-based tool and may not capture complex sarcasm or context-specific technical jargon. Its accuracy could be limited.\nRepresentativeness of Reddit: While large, our dataset is confined to Reddit and may not represent the full spectrum of public opinion on science and technology.\nStatic Topic Model: Our LDA model identifies topics from the entire corpus, which may not fully capture the evolution of topics over time.\n\n\n\nFuture Work\n\nAdvanced Sentiment Models: Fine-tune a transformer-based model (like BERT) on domain-specific data to achieve more accurate sentiment classification.\nDynamic Topic Modeling: Implement a Dynamic Topic Model (DTM) to explicitly track how the prevalence and meaning of topics change over time and in response to events.\nCausal Inference: Move beyond correlation to causal analysis by using statistical methods to determine the causal impact of specific events (e.g., a product launch) on community growth and sentiment."
  },
  {
    "objectID": "conclusion.html#technical-achievements",
    "href": "conclusion.html#technical-achievements",
    "title": "Conclusion and Recommendations",
    "section": "Technical Achievements",
    "text": "Technical Achievements\n\nBig Data Processing\n\nProcessed ~13.4 million rows of Reddit data (~12.6M comments, 0.8M submissions).\nUtilized a multi-node Apache Spark cluster on AWS for all data aggregation and model training, enabling analysis at a scale impossible on a single machine.\nAchieved efficient processing pipelines for EDA, NLP, and ML tasks.\n\n\n\nAnalytical Breadth\n\nEDA: Conducted large-scale statistical analysis of user activity, retention (user-set intersections), attention concentration (Gini coefficient), and community overlap (Jaccard similarity).\nNLP: Deployed scalable topic modeling (LDA), sentiment analysis (VADER), and rule-based text classification across millions of documents.\nML: Built and evaluated a binary classification (Logistic Regression) and an unsupervised clustering (K-Means) model using Spark MLlib, including feature engineering and performance evaluation on a massive dataset."
  },
  {
    "objectID": "conclusion.html#lessons-learned",
    "href": "conclusion.html#lessons-learned",
    "title": "Conclusion and Recommendations",
    "section": "Lessons Learned",
    "text": "Lessons Learned\n\nTechnical Lessons\n\nSpark is Essential for Scale: Analyzing millions of documents and user interactions would have been computationally infeasible without Spark’s distributed processing capabilities.\nFeature Engineering is Key: The performance of our ML models was heavily dependent on the quality of features engineered from raw text and metadata. Simple models with good features can be surprisingly effective.\nInfrastructure Automation: Automating the setup and teardown of the Spark cluster was critical for iterative development and cost management.\n\n\n\nDomain Lessons\n\nReddit is Not a Monolith: Tech and science communities on Reddit are incredibly diverse, ranging from highly technical forums to broad, future-focused discussion hubs. A one-size-fits-all approach to analysis or engagement is bound to fail.\nConversation is Resilient: Despite the fast-paced news cycle, the core themes and emotional tone of these communities are remarkably stable, pointing to a mature and established discourse."
  },
  {
    "objectID": "conclusion.html#final-thoughts",
    "href": "conclusion.html#final-thoughts",
    "title": "Conclusion and Recommendations",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nThis project successfully navigated the complexities of big data analytics to transform a massive, unstructured dataset into a clear narrative about the evolution of online science and technology communities. We moved from foundational data processing and exploration to sophisticated natural language processing and predictive modeling, uncovering actionable insights at each stage. Our findings not only answer our initial business questions but also provide a robust framework for any organization seeking to engage with and understand the powerful forces shaping public discourse on technology."
  },
  {
    "objectID": "conclusion.html#acknowledgments",
    "href": "conclusion.html#acknowledgments",
    "title": "Conclusion and Recommendations",
    "section": "Acknowledgments",
    "text": "Acknowledgments\n\nTeam Members: Chenxi Guo, Linjin He, Xiaoya Meng\nCourse: DSAN 6000 Big Data Analytics and Cloud Computing\nTools: Apache Spark, PySpark, Quarto, Python\nData Source: Reddit via Pushshift archives"
  },
  {
    "objectID": "report.html",
    "href": "report.html",
    "title": "Project Report",
    "section": "",
    "text": "Every day, millions of people gather on Reddit to make sense of rapid technological change. Some come to celebrate new AI breakthroughs, others to troubleshoot code, debate ethics, or simply share curiosity about the future. These conversations unfold across fragmented subreddits—each with its own tone, norms, and pace—yet they are all part of a broader ecosystem reacting in real time to the accelerating world of science and technology.\nAs AI tools reshape how people work, create, and communicate, online communities have become one of the most important places where public understanding takes shape. But despite the scale and influence of these spaces, we still know surprisingly little about how they evolve, what drives engagement, and how different groups organize around emerging technologies.\nThis leads to our core question:\nHow do online science and technology communities on Reddit evolve, interact, and structure their discussions around AI and emerging technologies?"
  },
  {
    "objectID": "report.html#introduction",
    "href": "report.html#introduction",
    "title": "Project Report",
    "section": "",
    "text": "Every day, millions of people gather on Reddit to make sense of rapid technological change. Some come to celebrate new AI breakthroughs, others to troubleshoot code, debate ethics, or simply share curiosity about the future. These conversations unfold across fragmented subreddits—each with its own tone, norms, and pace—yet they are all part of a broader ecosystem reacting in real time to the accelerating world of science and technology.\nAs AI tools reshape how people work, create, and communicate, online communities have become one of the most important places where public understanding takes shape. But despite the scale and influence of these spaces, we still know surprisingly little about how they evolve, what drives engagement, and how different groups organize around emerging technologies.\nThis leads to our core question:\nHow do online science and technology communities on Reddit evolve, interact, and structure their discussions around AI and emerging technologies?"
  },
  {
    "objectID": "report.html#dataset",
    "href": "report.html#dataset",
    "title": "Project Report",
    "section": "Dataset",
    "text": "Dataset\nThe dataset combines public Reddit comments and submissions across 100 subreddits, covering AI, programming, technology, and science. It contains over 12.5 million rows and spans from June 2023 to July 2024, providing a comprehensive view of user activity and discussions in these domains."
  },
  {
    "objectID": "report.html#method",
    "href": "report.html#method",
    "title": "Project Report",
    "section": "Method",
    "text": "Method\nWe analyzed Reddit submissions and comments from science, technology, and AI communities using a combination of EDA, natural language processing (NLP), and machine learning techniques.\nData were processed with Apache Spark, aggregating posts and comments by subreddit and month to compute community activity, user retention, and attention concentration metrics.\nNLP features included text cleaning, tokenization, stopword removal, TF-IDF or CountVectorizer encoding, topic modeling (LDA), sentiment analysis (VADER/TextBlob), and rule-based discussion type classification.\nMachine learning involved Logistic Regression to predict comment quality using text and behavioral features (e.g., comment length, URL presence, posting time) and K-Means clustering (with PCA visualization) to identify distinct discussion communities."
  },
  {
    "objectID": "report.html#business-questions-and-technical-approaches",
    "href": "report.html#business-questions-and-technical-approaches",
    "title": "Project Report",
    "section": "10 Business Questions and technical approaches",
    "text": "10 Business Questions and technical approaches\nSee BUSINESS_QUESTIONS.md"
  },
  {
    "objectID": "report.html#main-analysis",
    "href": "report.html#main-analysis",
    "title": "Project Report",
    "section": "Main Analysis",
    "text": "Main Analysis\nThis section provides an integrated overview of insights from the three analytical components of the project: Exploratory Data Analysis (EDA), Natural Language Processing (NLP), and Machine Learning (ML). Each subsection summarizes the key discoveries and links to a dedicated analysis page that documents interactive visuals, methodological details, and complete result sets.\n\nExploratory Data Analysis (EDA)\nThe EDA characterizes structural patterns in community behavior across 40 AI and technology subreddits by examining activity dynamics, user retention, attention allocation, and cross-community participation. Across the 14 months, community activity displays a hybrid pattern: broad technology subreddits maintain high baseline volume, while AI-focused forums exhibit episodic spikes aligned with major releases and public announcements. This separation reflects different drivers of participation, general technological interest versus AI-specific event sensitivity.\nUser retention analysis further distinguishes communities by functional role. Mainstream AI subreddits (e.g., ChatGPT, MachineLearning) maintain stable return rates, indicating sustained month-to-month engagement. At the same time, niche or highly specialized communities show short, high-intensity retention bursts tied to topic relevance. These patterns indicate that community size and topic breadth shape long-term participation capacity.\nAttention distribution also varies systematically across subreddit types. High-traffic communities exhibit an intense concentration of engagement with comment activity disproportionately captured by a small number of threads consistent with viral or news-driven dynamics. In contrast, technical and research-oriented subreddits (such as Machine Learning and Data Science) show lower attention inequality, supporting more evenly distributed, parallel discussions that align with expert-driven or problem-solving interactions.\nFinally, user-overlap analysis reveals minimal cross-participation between AI and technology communities, even among subreddits addressing closely related topics. This indicates that Reddit’s AI ecosystem consists of distinct audience segments, each interacting primarily within its own topical domain rather than migrating across adjacent communities.\nTogether, these EDA results identify apparent structural differences in how AI and technology communities behave, including activity drivers, engagement stability, attention allocation, and user segmentation, providing the analytical foundation for the NLP and ML components of the project.\nSee full analysis in Exploratory Data Analysis\n\n\nNatural Language Processing (NLP)\nThe NLP analysis examines the semantic structure, emotional tone, event responsiveness, and user-driven discussion patterns across 40 AI and technology-related subreddits. Topic modeling reveals a stable set of thematic structures centered on future-oriented technology, human–AI relations, practical learning and project development, programming workflows, and technology-driven business applications. After excluding a significant general conversational topic, the remaining themes remain remarkably consistent throughout the 14 months, indicating that community interests are persistent and not subject to substantial drift. These findings suggest that discussions in fast-growing AI and technology communities are shaped by enduring concerns about technological impact, career development, and practical implementation rather than short-lived trends.\nSentiment analysis using VADER further demonstrates that the emotional tone across all major communities is predominantly neutral to mildly positive. Average sentiment scores remain stable over time, with only modest fluctuations in AI-focused subreddits around major product announcements or regulatory milestones such as the Gemini release or the EU AI Act. These shifts, however, are short-lived and do not meaningfully alter the long-term emotional landscape. Programming, science, and broader technology communities show even less sensitivity to external events, reinforcing the conclusion that discourse in these communities is informational and measured rather than reactive or volatile.\nTo understand how users contribute to different forms of discourse, discussions were categorized into technical, ethical, societal, and general content. Technical discussions emphasize model architectures, data workflows, and computational methods; ethical discussions focus on fairness, regulation, and governance; societal discussions address employment, corporate influence, and broader social implications; and general discussions reflect meta-talk, moderation, or uncategorized exchanges. These distinctions reveal parallel layers of conversation, each shaped by distinct user groups with different informational needs and priorities.\nOverall, the NLP analysis shows that Reddit’s AI and technology discussions form a stable, multidimensional discourse environment. Community conversations are thematically coherent, emotionally steady, and only marginally influenced by external technological or policy events. Users contribute across diverse topical layers—from technical implementation to societal impact—indicating a mature and sustained public engagement with emerging technologies.\nSee full analysis in Natural Language Processing\n\n\nMachine Learning (ML)\nThe ML analysis explores the predictability of comment quality and the identification of distinct discussion communities within Reddit’s AI and technology subreddits. Using a combination of text features and behavioral metrics, we applied classification and clustering models to uncover patterns in content quality and thematic segmentation.\nTo examine comment quality, we trained a Logistic Regression model using text features generated via Tokenizer → StopWordsRemover → HashingTF → IDF, along with behavioral features such as comment length, presence of URLs, and posting hour/day. The model is partially successful: it achieves high recall for general high-quality comments (≈71%) but low precision (≈22%), while highly popular comments and low-quality comments show moderate recall and very low precision. These results indicate that the model is suitable for flagging candidate comments for manual review rather than for fully automated moderation, and that further improvement would require richer semantic representations and additional features.\nFor community detection, we combined submission titles and selftext to generate TF-IDF features, then applied K-Means clustering (K=13) with PCA visualization. The analysis revealed that most submissions (≈98%) cluster into everyday, general discussion groups, while a small portion (≈2%) forms tightly focused technical/programming clusters. This demonstrates that language-based clustering can separate broad conversational communities from specialized technical discussions, providing a foundation for downstream analyses such as sentiment tracking, engagement prediction, and content segmentation.\nSee full analysis in Machine Learning"
  },
  {
    "objectID": "report.html#business-recommendations",
    "href": "report.html#business-recommendations",
    "title": "Project Summary",
    "section": "Business Recommendations",
    "text": "Business Recommendations\nOur findings suggest several strategic recommendations for engaging with Reddit’s science and technology communities:\n\nAlign with Key Events: Capitalize on the event-driven nature of AI subreddits by timing announcements and content to coincide with major industry milestones.\nTailor Content to the Audience: Differentiate between technical and general-interest communities. Provide in-depth content for niche forums and high-level, concise narratives for broader ones.\nFocus on High-Impact Threads: In large subreddits, strategically engage in viral or high-visibility posts to maximize influence and shape community sentiment.\nLeverage the Constructive Environment: The stable, neutral-to-positive sentiment provides a safe space for organizations to contribute expert insights and educational content.\nUse ML for Triage, Not Automation: While our predictive models have high recall, their precision is limited. Use them to flag content for human review rather than for fully automated moderation.\nSegment Engagement Strategies: Recognize that most discussions are casual. Develop broad, conversational content for the majority, while reserving targeted, technical material for specialized subgroups to improve engagement efficiency."
  },
  {
    "objectID": "report.html#future-work",
    "href": "report.html#future-work",
    "title": "Project Summary",
    "section": "Future Work",
    "text": "Future Work\nFuture work could extend this analysis in several promising directions:\n\nAdvanced Modeling: Improve predictive accuracy by using contextual language embeddings (e.g., BERT), richer metadata, and more sophisticated classifiers like gradient boosting or transformers.\nNuanced Community Detection: Employ hierarchical or density-based clustering to uncover more subtle community structures and integrate these findings into forecasting models.\nLongitudinal and Causal Analysis: Extend the analysis over a longer timeframe to track multi-year evolution and integrate external datasets (e.g., news sentiment, policy timelines) to establish causal links between real-world events and online discourse.\nForecasting Pipelines: Develop a full forecasting pipeline to predict subreddit-level sentiment and activity, enabling proactive communication and engagement strategies."
  },
  {
    "objectID": "ml.html",
    "href": "ml.html",
    "title": "Machine Learning",
    "section": "",
    "text": "In this milestone, we harness the power of Apache Spark’s MLlib to explore and analyze Reddit discussions in science, technology, and AI communities. By applying a suite of machine learning techniques, we aim to uncover patterns in user behavior and comment content, and use these insights to tackle two key business questions. Through classification and regression models, we translate raw textual and behavioral data into actionable predictions, providing a deeper understanding of comment quality and the structure of discussion communities across technology-related subreddits."
  },
  {
    "objectID": "ml.html#overview",
    "href": "ml.html#overview",
    "title": "Machine Learning",
    "section": "",
    "text": "In this milestone, we harness the power of Apache Spark’s MLlib to explore and analyze Reddit discussions in science, technology, and AI communities. By applying a suite of machine learning techniques, we aim to uncover patterns in user behavior and comment content, and use these insights to tackle two key business questions. Through classification and regression models, we translate raw textual and behavioral data into actionable predictions, providing a deeper understanding of comment quality and the structure of discussion communities across technology-related subreddits."
  },
  {
    "objectID": "ml.html#business-question-1-your-ml-question",
    "href": "ml.html#business-question-1-your-ml-question",
    "title": "Machine Learning",
    "section": "Business Question 1: [Your ML Question]",
    "text": "Business Question 1: [Your ML Question]\nQuestion: [Full question text]\n\nProblem Formulation\n\nTask Type: [Classification / Regression / Clustering]\nTarget Variable: [What you’re predicting]\nEvaluation Metric: [Primary metric]\n\n\n\nFeature Engineering\nFeatures Used:\n\n[Feature category 1]\n[Feature category 2]\n[Feature category 3]\n\n\n\nModel Performance\n[Visualization: ROC curve, confusion matrix, etc.]\nResults:\n\nAccuracy: [value]\nPrecision: [value]\nRecall: [value]\nF1 Score: [value]"
  },
  {
    "objectID": "ml.html#feature-importance",
    "href": "ml.html#feature-importance",
    "title": "Machine Learning",
    "section": "Feature Importance",
    "text": "Feature Importance\n\nTop 10 Most Important Features\n[Visualization and table]"
  },
  {
    "objectID": "ml.html#model-comparison",
    "href": "ml.html#model-comparison",
    "title": "Machine Learning",
    "section": "Model Comparison",
    "text": "Model Comparison\n[Table comparing different models tried]"
  },
  {
    "objectID": "ml.html#summary",
    "href": "ml.html#summary",
    "title": "Machine Learning",
    "section": "Summary",
    "text": "Summary\n\nComment Quality is Partially Predictable: Logistic Regression models can identify high- and low-quality comments, but low precision makes them better suited for flagging content for manual review rather than for fully automated decisions. Model performance is limited by basic text features, suggesting a need for stronger semantic representations.\nDiscussion Communities are Identifiable and Distinct: K-Means clustering successfully grouped subreddits into two primary categories: broad Natural-Language/General Discussion (98%) and specialized Programming/Technical Content (2%). This clear separation provides a valuable foundation for feature engineering and targeted analysis."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Evolution of Online Science and Technology Communities on Reddit",
    "section": "",
    "text": "Chenxi Guo\nLinjin He\nXiaoya Meng"
  },
  {
    "objectID": "index.html#team-members",
    "href": "index.html#team-members",
    "title": "Evolution of Online Science and Technology Communities on Reddit",
    "section": "",
    "text": "Chenxi Guo\nLinjin He\nXiaoya Meng"
  },
  {
    "objectID": "index.html#project-overview",
    "href": "index.html#project-overview",
    "title": "Evolution of Online Science and Technology Communities on Reddit",
    "section": "Project Overview",
    "text": "Project Overview\nEvery day, millions of people gather on Reddit to make sense of rapid technological change. Some come to celebrate new AI breakthroughs, others to troubleshoot code, debate ethics, or simply share curiosity about the future. These conversations unfold across fragmented subreddits—each with its own tone, norms, and pace—yet they are all part of a broader ecosystem reacting in real time to the accelerating world of science and technology.\nAs AI tools reshape how people work, create, and communicate, online communities have become one of the most important places where public understanding takes shape. But despite the scale and influence of these spaces, we still know surprisingly little about how they evolve, what drives engagement, and how different groups organize around emerging technologies.\nThis leads to our core question:\nHigh-Level Problem:\nHow do online science and technology communities on Reddit evolve, interact, and structure their discussions around AI and emerging technologies?\n\nDataset\n\nSource: Reddit Comments and Submissions\nTime Period: 2023-06-01 to 2024-07-31\nSubreddits: 100 Total number of subreddits of science, technology, and AI-related subreddits, Covering AI, programming, technology, and science domains.\nScale: ~13.4 million rows (~12.6M comments, ~0.8M submissions)\nSize: ~13.4 GB\n\n\n\nBusiness Questions\nWe address 10 business questions spanning three analytical approaches:\nExploratory Data Analysis (EDA):\n\nHow has community activity evolved across science, technology, and AI subreddits over time?\nWhich technology-related subreddits demonstrate the strongest user engagement and retention over time?\nHow concentrated is attention within technology-related discussions (comments and scores)?\nDo science, technology, and AI subreddits share overlapping user communities?\n\nNatural Language Processing (NLP):\n\nWhat are the dominant topics and trends within fast-growing technology-related subreddits?\nWhat are the baseline emotional patterns of discussions about AI and emerging technologies?\nHow do external technological or policy events disrupt or reshape existing discussion patterns in online technology-related communities?\nHow do users shape topic emphasis and sentiment dynamics across science, technology, and AI subreddits?\n\nMachine Learning (ML):\n\nCan the Quality of Reddit Comments in Science, Technology, and AI Subreddits Be Predicted from comment content and basic behavioral features?\nCan distinct discussion communities be identified within technology-related subreddits based on patterns of language use?\n\nSee BUSINESS_QUESTIONS.md for detailed technical approaches."
  },
  {
    "objectID": "index.html#methodology",
    "href": "index.html#methodology",
    "title": "Evolution of Online Science and Technology Communities on Reddit",
    "section": "Methodology",
    "text": "Methodology\nWe analyzed Reddit submissions and comments from science, technology, and AI communities using a combination of EDA, natural language processing (NLP), and machine learning techniques. Data were processed with Apache Spark, aggregating posts and comments by subreddit and month to compute community activity, user retention, and attention concentration metrics. NLP features included text cleaning, tokenization, stopword removal, TF-IDF or CountVectorizer encoding, topic modeling (LDA), sentiment analysis (VADER/TextBlob), and rule-based discussion type classification. Machine learning involved Logistic Regression to predict comment quality using text and behavioral features (e.g., comment length, URL presence, posting time) and K-Means clustering (with PCA visualization) to identify distinct discussion communities.\n\nData Processing Infrastructure\n\nPlatform: Apache Spark cluster on AWS EC2\nProcessing: Distributed computing with PySpark\nStorage: Amazon S3 for data lake architecture\nScale: Processing over 13 million rows of text and metadata\n\n\n\nAnalysis Pipeline and Navigation\n\nData Acquisition & Filtering\n\nCopied and filtered a large public Reddit dataset to relevant subreddits and timeframes.\n\nExploratory Data Analysis → EDA Page\n\nAnalyzed temporal patterns, user engagement, attention concentration, and community overlap.\n\nNatural Language Processing → NLP Page\n\nDeployed topic modeling, sentiment analysis, and rule-based text classification.\n\nMachine Learning → ML Page\n\nTrained and evaluated classification and clustering models to predict content quality and identify user segments.\n\nFinal Conclusion → Conclusion\n\nSynthesized all findings into actionable insights and business recommendations.\n\nProject Report → Report\n\nSummarizes the entire project pipeline, highlights key findings, and provides a cohesive narrative linking methods, results, and business relevance."
  },
  {
    "objectID": "index.html#key-findings-preview",
    "href": "index.html#key-findings-preview",
    "title": "Evolution of Online Science and Technology Communities on Reddit",
    "section": "Key Findings Preview",
    "text": "Key Findings Preview\n\nMajor Insights\n\nCommunity Engagement is Event-Driven but Emotionally Stable: User activity surges in response to major AI product launches and news, but the overall emotional tone of the communities remains consistently neutral-to-positive, showing high resilience.\nA Core, Interconnected AI Community Drives the Conversation: A handful of central AI-focused subreddits (like r/ChatGPT, r/OpenAI) share a large, active user base, acting as the primary hub for discourse that spreads to the wider tech ecosystem.\nMost Conversations Are Casual, with a Few Tight-Knit Tech Corners: Our research reveals that the vast majority of submissions (≈98%) cluster into everyday, natural-language discussions, while only a small portion (≈2%) forms specialized technical or programming clusters.\n\n\n\nBusiness Impact\nOur findings provide a roadmap for understanding and engaging with online technology communities. By identifying key hubs of conversation, understanding the stable emotional climate, and leveraging ML for content curation, organizations can develop more efficient and impactful communication and community management strategies."
  },
  {
    "objectID": "index.html#repository",
    "href": "index.html#repository",
    "title": "Evolution of Online Science and Technology Communities on Reddit",
    "section": "Repository",
    "text": "Repository\n\nGitHub: https://github.com/gu-dsan6000/fall-2025-project-team29\nDocumentation: Comprehensive project details, methodology, and results are presented on this website. All source code and data outputs can be found in the GitHub repository.\n\n\nLast updated: December 6, 2025"
  },
  {
    "objectID": "EDA_WEB.html",
    "href": "EDA_WEB.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "This section presents a comprehensive exploratory data analysis (EDA) of user activity across 46 major AI and technology-focused subreddits from June 2023 to July 2024. By processing a large-scale dataset of over 12 million comments and 800,000 submissions with Spark and Python, we investigate four key business questions. Our analysis uncovers temporal activity patterns, quantifies user engagement and retention, measures attention inequality in discussions, and maps the landscape of cross-community user overlap. These findings provide a foundational understanding of the behavioral dynamics shaping the Reddit AI and technology ecosystem."
  },
  {
    "objectID": "EDA_WEB.html#data-overview",
    "href": "EDA_WEB.html#data-overview",
    "title": "Exploratory Data Analysis",
    "section": "Data Overview",
    "text": "Data Overview\n\nDataset Summary\nThis project analyzes a large-scale Reddit dataset covering user activity from June 2023 to July 2024 across 46 unique subreddits, enabling a comprehensive examination of engagement patterns and community dynamics.\nThe dataset’s overall scope is detailed in Table 1. It comprises over 12.5 million comments and 831,000 submissions, providing a rich foundation for analyzing user-generated content and discussion patterns.\nDataset Summary by Data Type\n\n\n\n\n\n\n\n\n\n\nData Type\nTotal Rows\nSize (GB)\nDate Range Start\nDate Range End\n\n\n\n\ncomments\n12,561,291\n12.56\n2023-06-01\n2024-07-31\n\n\nsubmissions\n831,021\n0.83\n2023-06-01\n2024-07-31\n\n\n\nAmong the 46 communities, activity is highly concentrated in a few key subreddits. The top five, measured by the total number of comments and submissions, are:\n\ntechnology — 3,265,248 total rows\n\nChatGPT — 1,894,755 total rows\n\nscience — 1,051,336 total rows\n\ncscareerquestions — 974,990 total rows\n\nFuturology — 914,347 total rows\n\nTo facilitate temporal analysis, this raw data was aggregated into monthly activity counts. Table 2 provides a sample of this structured data, which is used to explore activity trends in Business Question 1.\nSample of Monthly Activity Data\n\n\n\n\n\n\n\n\n\n\nsubreddit\nmonth\nposts\ncomments\ntotal_activity\n\n\n\n\nArtificialInteligence\n2023-06-01\n1900\n11962\n13862\n\n\nArtificialInteligence\n2023-07-01\n1829\n12078\n13907\n\n\nArtificialInteligence\n2023-08-01\n1759\n9922\n11681\n\n\nChatGPT\n2023-06-01\n11357\n139633\n150990\n\n\nChatGPT\n2023-07-01\n10597\n142224\n152821\n\n\nChatGPT\n2023-08-01\n10431\n131996\n142427"
  },
  {
    "objectID": "EDA_WEB.html#rq1-how-has-community-activity-evolved-across-ai-and-technology-subreddits-over-time",
    "href": "EDA_WEB.html#rq1-how-has-community-activity-evolved-across-ai-and-technology-subreddits-over-time",
    "title": "Exploratory Data Analysis",
    "section": "RQ1: How has community activity evolved across AI and technology subreddits over time?",
    "text": "RQ1: How has community activity evolved across AI and technology subreddits over time?\nBusiness Question:\nHow have monthly post and comment volumes changed across major AI and technology subreddits? Do any noticeable surges correspond to major AI or technology events?\nAnalysis Approach:\n- Use Spark to aggregate posts and comments by subreddit and month\n- Visualize monthly activity trends to compare engagement patterns and identify periods of rapid growth or decline\n\n\n\n\n\n\n\n\n\nFindings:\n- technology consistently dominates overall activity, peaking above 300,000 monthly interactions in mid-2023 and again in mid-2024, reflecting its broad and sustained user interest.\n- ChatGPT shows several pronounced surges—particularly around late 2023 and early 2024—likely corresponding to major AI announcements and product updates.\n- Futurology exhibits a steady upward trend throughout the year, suggesting growing interest in future-oriented and AI-related discussions.\n- OpenAI experiences sharp but short-lived spikes (e.g., late 2023 and mid-2024), consistent with event-driven engagement tied to major releases or public statements.\n- Smaller communities such as MachineLearning, technews, and ArtificialInteligence remain relatively stable, showing modest fluctuations but no large-scale surges.\nOverall, activity patterns indicate that major AI/tech events tend to drive short-term spikes in engagement, while broader technology interest maintains high baseline levels throughout the entire period."
  },
  {
    "objectID": "EDA_WEB.html#rq2-which-ai-related-subreddits-demonstrate-the-strongest-user-engagement-and-retention-over-time",
    "href": "EDA_WEB.html#rq2-which-ai-related-subreddits-demonstrate-the-strongest-user-engagement-and-retention-over-time",
    "title": "Exploratory Data Analysis",
    "section": "RQ2: Which AI-related subreddits demonstrate the strongest user engagement and retention over time?",
    "text": "RQ2: Which AI-related subreddits demonstrate the strongest user engagement and retention over time?\nBusiness Question:\nWhich AI communities successfully retain users across months—indicating sustained engagement—rather than attracting only short-term or event-driven traffic?\nAnalysis Approach:\n- Use Spark to compute the monthly returning-to-active user ratio for each subreddit as a proxy for retention.\n- Visualize retention trends with a heatmap to highlight which communities maintain consistent returning user activity over time.\n\n\n\n\n\n\n\n\n\nFindings:\n\nNiche AI communities exhibit sharp fluctuations in retention.\nSubreddits with smaller and more specialized audiences—such as Alethics—show periods of extremely high retention, with ratios reaching up to ~1.0 in certain months. This indicates that when these communities experience relevant discussions or bursts of interest, the majority of users who are active in those months tend to return. However, these peaks are intermittent, suggesting that engagement in niche communities is event-driven and highly sensitive to topical relevance rather than sustained momentum.\nMainstream AI subreddits maintain moderate but stable retention levels.\nLarger communities like ChatGPT, MachineLearning, and OpenAI display retention ratios that consistently fall within the 0.2–0.4 range. Although these values are lower than those of niche subreddits during their peak months, their stability reflects a healthier and more durable engagement structure: a substantial portion of users continue returning month over month, supported by continual content flow, broader topic coverage, and steady user inflow.\nTemporal patterns reveal community-specific engagement cycles.\nRetention for niche subreddits tends to be more volatile, with visible month-to-month jumps. This volatility suggests communities formed around narrow or emerging topics experience engagement surges only when new developments occur. In contrast, mainstream subreddits exhibit smoother seasonal variations that correspond more closely to long-term trends in AI and technology discourse.\nGeneral AI forums demonstrate stronger baseline cohesion.\nCommunities like MachineLearning and OpenAI do not show extreme highs or lows but instead maintain a persistent core of recurring users. This indicates well-established community identity and ongoing discussions that encourage users to return even outside of major events.\nOverall interpretation:\nThe heatmap highlights a clear divide between niche and broad AI communities. Niche subreddits achieve high short-term engagement but lack consistency, while mainstream subreddits sustain steady returning-user activity, suggesting stronger community cohesion and long-term user retention. These patterns underline how topic breadth, community size, and event-driven interest all influence user retention dynamics across Reddit’s AI ecosystem."
  },
  {
    "objectID": "EDA_WEB.html#rq3-how-concentrated-is-attention-within-ai-and-tech-discussions",
    "href": "EDA_WEB.html#rq3-how-concentrated-is-attention-within-ai-and-tech-discussions",
    "title": "Exploratory Data Analysis",
    "section": "RQ3: How concentrated is attention within AI and tech discussions?",
    "text": "RQ3: How concentrated is attention within AI and tech discussions?\nBusiness Question:\nTo what extent are conversations driven by a small number of highly viral posts, versus being distributed more evenly across many posts? In other words, do certain subreddits exhibit stronger attention inequality than others?\nAnalysis Approach:\n- Use Spark to compute the Gini coefficient of comments per post for each subreddit, where higher Gini values indicate more concentrated attention.\n- Visualize distribution patterns using violin plots to show variability across months and bar charts to compare average attention concentration between subreddits.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFindings:\n\nTechnology and ChatGPT exhibit the strongest concentration of attention, with average Gini values approaching 0.88–0.90.\nThis indicates that engagement in these subreddits is dominated by a handful of highly viral posts. When major announcements, controversies, or breakthrough AI tools emerge, these communities often experience rapid surges in attention focused on a small number of trending threads. As a result, the distribution of comments becomes heavily skewed: most posts receive modest engagement while a small set of “blockbuster” discussions absorb the majority of user activity. Such dynamics are typical of large, heterogeneous audiences that respond quickly to broad-interest or news-driven content.\nProfessional and technical communities—including MachineLearning and datascience—show significantly lower attention inequality (Gini ≈ 0.70–0.78).\nThese subreddits display a more evenly distributed engagement pattern, where comments accumulate across a wider range of posts rather than concentrating around a few viral threads. This suggests that discussions are more specialized, sustained, and topic-focused, attracting recurring contributions from users who are participating for informational or expert-driven purposes rather than reacting to viral events. The lower Gini values imply that these communities support richer, multi-thread parallel discussions typical of technical forums.\nOpenAI occupies a middle ground, with moderate concentration levels (~0.75–0.80) but higher variability across months.\nThis pattern reflects the community’s sensitivity to event-driven cycles: during major OpenAI releases or controversies, a few posts dominate the discourse, while in quieter periods, engagement becomes more evenly distributed.\nOverall, the Gini-based comparisons highlight a structural divide between general-interest and expert-focused AI communities.\nLarge, news-oriented subreddits tend to exhibit “winner-take-most” behavior, where viral content disproportionately shapes the conversation. In contrast, subreddits centered on technical learning, research, or professional practice support more equitable attention patterns, indicating a healthier distribution of dialogue across diverse posts. These findings reveal how audience composition, content type, and topic breadth jointly influence the way discussions unfold within online AI and technology communities."
  },
  {
    "objectID": "EDA_WEB.html#rq4-do-ai-and-technology-subreddits-share-overlapping-user-communities",
    "href": "EDA_WEB.html#rq4-do-ai-and-technology-subreddits-share-overlapping-user-communities",
    "title": "Exploratory Data Analysis",
    "section": "RQ4: Do AI and technology subreddits share overlapping user communities?",
    "text": "RQ4: Do AI and technology subreddits share overlapping user communities?\nBusiness Question:\nTo what extent do users participate across multiple AI and technology subreddits? Are some communities closely interconnected through shared user bases, while others attract distinct, non-overlapping audiences?\nAnalysis Approach:\n\nExtract unique users from each subreddit using Spark.\nCompute pairwise Jaccard similarity to quantify user overlap.\nVisualize the subreddit-to-subreddit similarity matrix using a heatmap to highlight shared and distinct audience patterns.\n\n\n\n\n\n\n\n\n\n\nFindings:\n\nOverall user overlap across the selected AI and technology subreddits is low, with most Jaccard similarity values close to zero. This indicates that these communities attract largely distinct audiences rather than sharing a common user base.\nGeneral-interest subreddits such as technology and technews show only weak connections to more specialized communities (e.g., MachineLearning, robotics, OpenAI), suggesting that mainstream tech discussions do not substantially overlap with expert-driven or AI-focused forums.\nSimilarly, AI-related subreddits such as ChatGPT, OpenAI, and ArtificialInteligence do not exhibit strong user overlap with one another, implying that users tend to engage in platform- or topic-specific communities rather than participating broadly across the AI ecosystem.\nThe near-diagonal heatmap pattern reinforces the idea that each subreddit represents a relatively independent audience segment, with minimal cross-community engagement or user migration during the study period."
  },
  {
    "objectID": "EDA_WEB.html#key-takeaways",
    "href": "EDA_WEB.html#key-takeaways",
    "title": "Exploratory Data Analysis",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nCommunity activity is highly event-driven, with major AI/tech announcements producing clear surges in monthly posts and comments. Among all communities, the technology subreddit consistently maintains the highest baseline activity, highlighting its broad relevance and responsiveness to industry-wide events.\nUser retention patterns differ sharply across subreddit types. Specialized communities (e.g., science, robotics) show intermittent but intense periods of returning-user engagement, whereas larger mainstream AI communities such as ChatGPT and technology exhibit more stable, steady retention, indicating continuous community participation.\nAttention concentration varies with community purpose. General tech forums display high Gini coefficients (≈0.9), suggesting a “viral hit” structure where a few posts dominate engagement. In contrast, technical and research-focused subreddits (e.g., MachineLearning) distribute attention more evenly (Gini ≈0.7), supporting sustained, multi-threaded discussions rather than viral dynamics.\nCross-community user overlap is minimal, showing that AI and technology subreddits maintain largely distinct audience groups. Even closely related AI subreddits share limited user participation, indicating strong topical specialization rather than fluid cross-community engagement."
  },
  {
    "objectID": "nlp.html",
    "href": "nlp.html",
    "title": "Natural Language Processing",
    "section": "",
    "text": "This study employs Natural Language Processing (NLP) techniques to investigate discussions related to Technology, Science, and Artificial Intelligence on Reddit. We analyze community discourse across multiple subreddits to identify dominant topics, track sentiment trends over time, and explore thematic differences in ethical, technical, and societal discussions. Methods include Latent Dirichlet Allocation (LDA) for topic modeling, VADER for sentiment analysis, and rule-based text classification to generate word clouds, providing both quantitative and visual insights into the semantic structure and community focus within AI- and technology-related discussions."
  },
  {
    "objectID": "nlp.html#overview",
    "href": "nlp.html#overview",
    "title": "Natural Language Processing",
    "section": "",
    "text": "This study employs Natural Language Processing (NLP) techniques to investigate discussions related to Technology, Science, and Artificial Intelligence on Reddit. We analyze community discourse across multiple subreddits to identify dominant topics, track sentiment trends over time, and explore thematic differences in ethical, technical, and societal discussions. Methods include Latent Dirichlet Allocation (LDA) for topic modeling, VADER for sentiment analysis, and rule-based text classification to generate word clouds, providing both quantitative and visual insights into the semantic structure and community focus within AI- and technology-related discussions."
  },
  {
    "objectID": "nlp.html#business-question-1-your-nlp-question",
    "href": "nlp.html#business-question-1-your-nlp-question",
    "title": "Natural Language Processing",
    "section": "Business Question 1: [Your NLP Question]",
    "text": "Business Question 1: [Your NLP Question]\nQuestion: [Full question text]\n\nFindings\n[Visualization placeholder]\nKey Insights:\n\n[Insight 1]\n[Insight 2]"
  },
  {
    "objectID": "nlp.html#sentiment-analysis",
    "href": "nlp.html#sentiment-analysis",
    "title": "Natural Language Processing",
    "section": "Sentiment Analysis",
    "text": "Sentiment Analysis\n\nOverall Sentiment Distribution\n[Description and visualization]\n\n\nSentiment by Subreddit\n[Comparison visualization]"
  },
  {
    "objectID": "nlp.html#topic-modeling",
    "href": "nlp.html#topic-modeling",
    "title": "Natural Language Processing",
    "section": "Topic Modeling",
    "text": "Topic Modeling\n\nDiscovered Topics\nTopic 1: [Topic Name]\n\nKeywords: [keywords]\n\nTopic 2: [Topic Name]\n\nKeywords: [keywords]"
  },
  {
    "objectID": "nlp.html#summary",
    "href": "nlp.html#summary",
    "title": "Natural Language Processing",
    "section": "Summary",
    "text": "Summary\nThis NLP analysis of Reddit discussions reveals a stable and thematically rich discourse environment:\n\nDominant Topics are Future-Oriented and Practical: After filtering out general chatter, the most significant topics revolve around human-AI relations, career and skill development, and the intersection of technology and business. This indicates a community focused on both the philosophical implications and practical applications of AI.\nSentiment is Consistently Neutral-to-Positive: The vast majority of discussions are objective and informative rather than emotionally charged. A persistent positive skew suggests a generally constructive and optimistic atmosphere across most technology and AI subreddits.\nDiscourse is Resilient to External Events: Despite a volatile year of AI news, both topic distribution and overall sentiment remained remarkably stable. Major product launches or policy decisions caused only minor, short-lived sentiment shifts in highly specialized AI forums, indicating a mature and resilient discussion landscape.\nDiscussions are Thematically Distinct: Users naturally segment conversations into clear categories. Ethical discussions focus on governance and bias, societal discussions on jobs and real-world impact, and technical discussions on the mechanics of AI models, each with its own distinct vocabulary."
  },
  {
    "objectID": "BUSINESS_QUESTIONS.html",
    "href": "BUSINESS_QUESTIONS.html",
    "title": "Project: Evolution of Online Science and Technology Communities on Reddit",
    "section": "",
    "text": "Team: Chenxi Guo, Linjin He, Xiaoya Meng\nDataset: Reddit comments and submissions (filtered for science, technology, and AI subreddits, ~hundreds of millions of rows)\nHigh-Level Problem Statement: How do online science and technology communities on Reddit evolve, interact, and structure their discussions around AI and emerging technologies?\n\n\n\nAnalysis Type: EDA\nTechnical Approach:\n\nUse Spark to load S3 parquet data (submissions + comments), filter target subreddits and date range.\nAggregate posts and comments by subreddit and month (distinct ids) and compute total activity per month.\nExport CSV and visualize monthly activity trends (line charts) to compare engagement patterns and identify rapid growth or decline periods.\n\n\n\n\n\nAnalysis Type: EDA\nTechnical Approach:\n\nUse Spark to extract distinct active users per subreddit and month (union of comments and submissions authors).\nCompute monthly returning-to-active user ratio using set intersections across adjacent months (window lag) as a proxy for retention.\nExport CSV and visualize retention with a heatmap to highlight communities with consistent returning activity.\n\n\n\n\n\nAnalysis Type: EDA\nTechnical Approach:\n\nUse Spark to compute per-post statistics (comments per post and post scores) for each subreddit and month.\nCompute Gini coefficients over collected lists (comments per post, and separately post scores) via a UDF to measure attention concentration.\nExport results and visualize distributions with violin plots and sorted bar charts comparing average concentration across subreddits.\n\n\n\n\n\nAnalysis Type: EDA\nTechnical Approach:\n\nUse Spark to collect unique authors per subreddit (from comments and submissions).\nCompute pairwise Jaccard similarity (size of intersection / size of union) between subreddit user sets.\nExport the similarity matrix and visualize it as a heatmap to reveal shared vs. distinct audiences.\n\n\n\n\n\nAnalysis Type: NLP\nTechnical Approach:\n\nCombine submissions (title + selftext) and comments, preprocess text (lowercasing, URL removal, non-letter removal, tokenization, stopword removal).\nUse Spark ML: CountVectorizer (term counts) → IDF (TF-IDF-style weighting) → LDA to discover topics.\nExtract top keywords per topic and analyze topic prevalence over time and across subreddits; save topic trends and topic-by-subreddit tables to CSV/S3 and generate visualizations (topic trends, heatmaps, keyword bars, pie charts).\nExpected outcome: Identify trending discussions and emerging themes (e.g., regulation, ethics, tooling, applications).\n\n\n\n\n\nAnalysis Type: NLP\nTechnical Approach:\n\nPreprocess and combine comments and submissions; apply VADER (VaderSentiment / NLTK VADER) via a Spark UDF to compute compound sentiment scores per document.\nAggregate monthly or subreddit-level average sentiment scores and sentiment-category distributions; export CSVs and visualize trends, subreddit comparisons, and stacked sentiment distributions/heatmaps.\nExpected outcome: Detect optimism, skepticism, or ethical concerns and how they vary by community and time.\n\n\n\n\n\nAnalysis Type: NLP\nTechnical Approach:\n\nAlign time series of sentiment (from Q6) and topic prevalence (from Q5) with an event timeline (e.g., model releases, major product announcements, policy milestones).\nDetect before/after changes in discussion volume, dominant topics, or sentiment averages; visualize event-aligned comparisons (vertical event markers on time series plots).\nExpected outcome: Understand the short-term and medium-term impact of external events on community perception and topic emphasis.\n\n\n\n\n\nAnalysis Type: NLP\nTechnical Approach:\n\nUse rule-based keyword/topic assignment to classify documents into discussion types (example implementation: “technical”, “ethical”, “societal”, “other”).\nAggregate counts and generate visual summaries (word clouds per class, frequency by subreddit, temporal counts). The existing implementation focuses on keyword-based classification and visual inspection (word clouds); correlation with engagement metrics is possible but not currently implemented in the code.\nExpected outcome: Identify which discussion types dominate different subreddreads and their representative keywords/semantic fields.\n\n\n\n\n\nAnalysis Type: ML\nTechnical Approach:\n\nLabel comments as high-quality using a score threshold (implementation: score &gt;= 6 → positive label).\nFeature engineering includes text features produced by Tokenizer → StopWordsRemover → HashingTF → IDF (text_features), plus numeric/behavioral features (comment length, presence of URL, hour_of_day, day_of_week). Class weighting is applied to address imbalance.\nTrain a Spark ML pipeline with Logistic Regression and evaluate on test data with accuracy, precision, recall, F1, ROC/AUC, and confusion matrix; save model and output metrics.\nExpected outcome: Predict high-engagement/high-quality comments and report model performance.\n\n\n\n\n\nAnalysis Type: ML\nTechnical Approach:\n\nCombine title and selftext to create document text, clean non-letter characters, and extract TF features using Tokenizer → StopWordsRemover → HashingTF → IDF (or CountVectorizer + IDF).\nUse K-Means clustering (implementation includes elbow method to choose K), apply PCA for 2D visualization, and save cluster assignments and a cluster analysis (cluster sizes and top terms per cluster). Optionally compute sentiment per cluster for interpretation (TextBlob used in the script for simple sentiment aggregation).\nExpected outcome: Identify distinct discussion directions, visualize cluster structure, and provide representative keywords per cluster.\n\n\n\n\n\nEDA Questions: 1, 2, 3, 4 (4 questions)\nNLP Questions: 5, 6, 7, 8 (4 questions)\nML Questions: 9, 10 (2 questions)"
  },
  {
    "objectID": "BUSINESS_QUESTIONS.html#question-1-how-has-community-activity-evolved-across-science-technology-and-ai-subreddits-over-time",
    "href": "BUSINESS_QUESTIONS.html#question-1-how-has-community-activity-evolved-across-science-technology-and-ai-subreddits-over-time",
    "title": "Project: Evolution of Online Science and Technology Communities on Reddit",
    "section": "",
    "text": "Analysis Type: EDA\nTechnical Approach:\n\nUse Spark to load S3 parquet data (submissions + comments), filter target subreddits and date range.\nAggregate posts and comments by subreddit and month (distinct ids) and compute total activity per month.\nExport CSV and visualize monthly activity trends (line charts) to compare engagement patterns and identify rapid growth or decline periods."
  },
  {
    "objectID": "BUSINESS_QUESTIONS.html#question-2-which-technology-related-subreddits-demonstrate-the-strongest-user-engagement-and-retention-over-time",
    "href": "BUSINESS_QUESTIONS.html#question-2-which-technology-related-subreddits-demonstrate-the-strongest-user-engagement-and-retention-over-time",
    "title": "Project: Evolution of Online Science and Technology Communities on Reddit",
    "section": "",
    "text": "Analysis Type: EDA\nTechnical Approach:\n\nUse Spark to extract distinct active users per subreddit and month (union of comments and submissions authors).\nCompute monthly returning-to-active user ratio using set intersections across adjacent months (window lag) as a proxy for retention.\nExport CSV and visualize retention with a heatmap to highlight communities with consistent returning activity."
  },
  {
    "objectID": "BUSINESS_QUESTIONS.html#question-3-how-concentrated-is-attention-within-technology-related-discussions-comments-and-scores",
    "href": "BUSINESS_QUESTIONS.html#question-3-how-concentrated-is-attention-within-technology-related-discussions-comments-and-scores",
    "title": "Project: Evolution of Online Science and Technology Communities on Reddit",
    "section": "",
    "text": "Analysis Type: EDA\nTechnical Approach:\n\nUse Spark to compute per-post statistics (comments per post and post scores) for each subreddit and month.\nCompute Gini coefficients over collected lists (comments per post, and separately post scores) via a UDF to measure attention concentration.\nExport results and visualize distributions with violin plots and sorted bar charts comparing average concentration across subreddits."
  },
  {
    "objectID": "BUSINESS_QUESTIONS.html#question-4-do-science-technology-and-ai-subreddits-share-overlapping-user-communities",
    "href": "BUSINESS_QUESTIONS.html#question-4-do-science-technology-and-ai-subreddits-share-overlapping-user-communities",
    "title": "Project: Evolution of Online Science and Technology Communities on Reddit",
    "section": "",
    "text": "Analysis Type: EDA\nTechnical Approach:\n\nUse Spark to collect unique authors per subreddit (from comments and submissions).\nCompute pairwise Jaccard similarity (size of intersection / size of union) between subreddit user sets.\nExport the similarity matrix and visualize it as a heatmap to reveal shared vs. distinct audiences."
  },
  {
    "objectID": "BUSINESS_QUESTIONS.html#question-5-what-are-the-dominant-topics-and-trends-within-fast-growing-technology-related-subreddits",
    "href": "BUSINESS_QUESTIONS.html#question-5-what-are-the-dominant-topics-and-trends-within-fast-growing-technology-related-subreddits",
    "title": "Project: Evolution of Online Science and Technology Communities on Reddit",
    "section": "",
    "text": "Analysis Type: NLP\nTechnical Approach:\n\nCombine submissions (title + selftext) and comments, preprocess text (lowercasing, URL removal, non-letter removal, tokenization, stopword removal).\nUse Spark ML: CountVectorizer (term counts) → IDF (TF-IDF-style weighting) → LDA to discover topics.\nExtract top keywords per topic and analyze topic prevalence over time and across subreddits; save topic trends and topic-by-subreddit tables to CSV/S3 and generate visualizations (topic trends, heatmaps, keyword bars, pie charts).\nExpected outcome: Identify trending discussions and emerging themes (e.g., regulation, ethics, tooling, applications)."
  },
  {
    "objectID": "BUSINESS_QUESTIONS.html#question-6-what-are-the-baseline-emotional-patterns-of-discussions-about-ai-and-emerging-technologies",
    "href": "BUSINESS_QUESTIONS.html#question-6-what-are-the-baseline-emotional-patterns-of-discussions-about-ai-and-emerging-technologies",
    "title": "Project: Evolution of Online Science and Technology Communities on Reddit",
    "section": "",
    "text": "Analysis Type: NLP\nTechnical Approach:\n\nPreprocess and combine comments and submissions; apply VADER (VaderSentiment / NLTK VADER) via a Spark UDF to compute compound sentiment scores per document.\nAggregate monthly or subreddit-level average sentiment scores and sentiment-category distributions; export CSVs and visualize trends, subreddit comparisons, and stacked sentiment distributions/heatmaps.\nExpected outcome: Detect optimism, skepticism, or ethical concerns and how they vary by community and time."
  },
  {
    "objectID": "BUSINESS_QUESTIONS.html#question-7-how-do-external-technological-or-policy-events-disrupt-or-reshape-existing-discussion-patterns-in-online-technology-related-communities",
    "href": "BUSINESS_QUESTIONS.html#question-7-how-do-external-technological-or-policy-events-disrupt-or-reshape-existing-discussion-patterns-in-online-technology-related-communities",
    "title": "Project: Evolution of Online Science and Technology Communities on Reddit",
    "section": "",
    "text": "Analysis Type: NLP\nTechnical Approach:\n\nAlign time series of sentiment (from Q6) and topic prevalence (from Q5) with an event timeline (e.g., model releases, major product announcements, policy milestones).\nDetect before/after changes in discussion volume, dominant topics, or sentiment averages; visualize event-aligned comparisons (vertical event markers on time series plots).\nExpected outcome: Understand the short-term and medium-term impact of external events on community perception and topic emphasis."
  },
  {
    "objectID": "BUSINESS_QUESTIONS.html#question-8-how-do-users-shape-topic-emphasis-and-sentiment-dynamics-across-science-technology-and-ai-subreddits",
    "href": "BUSINESS_QUESTIONS.html#question-8-how-do-users-shape-topic-emphasis-and-sentiment-dynamics-across-science-technology-and-ai-subreddits",
    "title": "Project: Evolution of Online Science and Technology Communities on Reddit",
    "section": "",
    "text": "Analysis Type: NLP\nTechnical Approach:\n\nUse rule-based keyword/topic assignment to classify documents into discussion types (example implementation: “technical”, “ethical”, “societal”, “other”).\nAggregate counts and generate visual summaries (word clouds per class, frequency by subreddit, temporal counts). The existing implementation focuses on keyword-based classification and visual inspection (word clouds); correlation with engagement metrics is possible but not currently implemented in the code.\nExpected outcome: Identify which discussion types dominate different subreddreads and their representative keywords/semantic fields."
  },
  {
    "objectID": "BUSINESS_QUESTIONS.html#question-9-can-the-quality-of-reddit-comments-in-science-technology-and-ai-subreddits-be-predicted-from-comment-content-and-basic-behavioral-features",
    "href": "BUSINESS_QUESTIONS.html#question-9-can-the-quality-of-reddit-comments-in-science-technology-and-ai-subreddits-be-predicted-from-comment-content-and-basic-behavioral-features",
    "title": "Project: Evolution of Online Science and Technology Communities on Reddit",
    "section": "",
    "text": "Analysis Type: ML\nTechnical Approach:\n\nLabel comments as high-quality using a score threshold (implementation: score &gt;= 6 → positive label).\nFeature engineering includes text features produced by Tokenizer → StopWordsRemover → HashingTF → IDF (text_features), plus numeric/behavioral features (comment length, presence of URL, hour_of_day, day_of_week). Class weighting is applied to address imbalance.\nTrain a Spark ML pipeline with Logistic Regression and evaluate on test data with accuracy, precision, recall, F1, ROC/AUC, and confusion matrix; save model and output metrics.\nExpected outcome: Predict high-engagement/high-quality comments and report model performance."
  },
  {
    "objectID": "BUSINESS_QUESTIONS.html#question-10-can-distinct-discussion-communities-be-identified-within-technology-related-subreddits-based-on-patterns-of-language-use",
    "href": "BUSINESS_QUESTIONS.html#question-10-can-distinct-discussion-communities-be-identified-within-technology-related-subreddits-based-on-patterns-of-language-use",
    "title": "Project: Evolution of Online Science and Technology Communities on Reddit",
    "section": "",
    "text": "Analysis Type: ML\nTechnical Approach:\n\nCombine title and selftext to create document text, clean non-letter characters, and extract TF features using Tokenizer → StopWordsRemover → HashingTF → IDF (or CountVectorizer + IDF).\nUse K-Means clustering (implementation includes elbow method to choose K), apply PCA for 2D visualization, and save cluster assignments and a cluster analysis (cluster sizes and top terms per cluster). Optionally compute sentiment per cluster for interpretation (TextBlob used in the script for simple sentiment aggregation).\nExpected outcome: Identify distinct discussion directions, visualize cluster structure, and provide representative keywords per cluster."
  },
  {
    "objectID": "BUSINESS_QUESTIONS.html#summary",
    "href": "BUSINESS_QUESTIONS.html#summary",
    "title": "Project: Evolution of Online Science and Technology Communities on Reddit",
    "section": "",
    "text": "EDA Questions: 1, 2, 3, 4 (4 questions)\nNLP Questions: 5, 6, 7, 8 (4 questions)\nML Questions: 9, 10 (2 questions)"
  },
  {
    "objectID": "NLP_WEB.html",
    "href": "NLP_WEB.html",
    "title": "Natural Language Processing",
    "section": "",
    "text": "This study employs Natural Language Processing (NLP) techniques to investigate discussions related to Technology, Science, and Artificial Intelligence on Reddit. We analyze community discourse across multiple subreddits to identify dominant topics, track sentiment trends over time, and explore thematic differences in ethical, technical, and societal discussions. Methods include Latent Dirichlet Allocation (LDA) for topic modeling, VADER for sentiment analysis, and rule-based text classification to generate word clouds, providing both quantitative and visual insights into the semantic structure and community focus within AI- and technology-related discussions."
  },
  {
    "objectID": "NLP_WEB.html#introduction",
    "href": "NLP_WEB.html#introduction",
    "title": "Natural Language Processing",
    "section": "",
    "text": "This study employs Natural Language Processing (NLP) techniques to investigate discussions related to Technology, Science, and Artificial Intelligence on Reddit. We analyze community discourse across multiple subreddits to identify dominant topics, track sentiment trends over time, and explore thematic differences in ethical, technical, and societal discussions. Methods include Latent Dirichlet Allocation (LDA) for topic modeling, VADER for sentiment analysis, and rule-based text classification to generate word clouds, providing both quantitative and visual insights into the semantic structure and community focus within AI- and technology-related discussions."
  },
  {
    "objectID": "NLP_WEB.html#business-question-5-what-are-the-dominant-topics-and-trends-within-fast-growing-technology-related-subreddits",
    "href": "NLP_WEB.html#business-question-5-what-are-the-dominant-topics-and-trends-within-fast-growing-technology-related-subreddits",
    "title": "Natural Language Processing",
    "section": "Business Question 5: What are the dominant topics and trends within fast-growing technology-related subreddits?",
    "text": "Business Question 5: What are the dominant topics and trends within fast-growing technology-related subreddits?\nAs shown in the figure, the Latent Dirichlet Allocation (LDA) model identifies ten distinct topics from the corpus, each represented by its most influential keywords. These keywords provide an interpretable summary of the semantic focus of each discovered topic.\nTopic 0 is characterized by keywords such as data, apple, ai, science, user, and marketing, suggesting that this topic centers on discussions related to data science, artificial intelligence, and technology-driven business practices.\nTopic 1 includes terms such as karma, comment, subreddit, message, and questions, indicating that it reflects conversations about community interactions, platform moderation, and posting behaviors within online forums such as Reddit.\nTopic 2 is defined by words like human, ai, power, energy, car, and years, representing discourse around human–AI relations, emerging technologies, and long-term trends in energy and transportation.\nTopic 3 contains keywords including word, images, water, read, and data, pointing to content associated with information extraction, text and image processing, and data-driven analysis.\nTopic 4 focuses on terms such as code, python, data, using, language, and windows, clearly corresponding to programming-related discussions involving software tools, coding practices, and computational workflows.\nTopic 5 includes reddit, app, api, change, party, commercial, and pricing, which collectively suggest themes related to application development, API usage, and commercial product or platform changes.\nTopic 6 is composed of more conversational keywords such as something, never, someone, bad, lol, and yeah, indicating informal, colloquial exchanges or personal expressions within the corpus.\nTopic 7 features terms like learn, help, project, learning, software, and job, pointing to discussions focused on learning resources, technical support, project development, and career-oriented themes.\nTopic 8 is defined by job, jobs, entrepreneur, pay, business, and company, representing topics related to employment, entrepreneurship, compensation, and broader business activities.\nTopic 9 includes keywords such as chatgpt, bot, prompt, conversation, post, and reply, indicating discourse involving conversational agents, prompt design, and user–system interactions.\nOverall, these topics illustrate the LDA model’s ability to uncover coherent thematic structures within the dataset and to organize large volumes of text into interpretable clusters.\n\n\n\nTopic keywords\n\n\n\nOverall Topic Distribution\nAs shown in the pie chart, the Latent Dirichlet Allocation (LDA) model identifies ten distinct topics. Before ranking them, it is crucial to address Topic 6.\nA Note on Topic 6 (General Conversational Topic): Topic 6 (22.4%), with keywords like something, never, someone, bad, lol, yeah, represents a “background” or “general conversational” topic. It captures common, low-specificity words and conversational filler that are prevalent across the entire dataset but do not form a coherent semantic theme. The emergence of such a topic is a common and expected artifact of LDA. For the purpose of identifying the most significant thematic discussions, we will exclude Topic 6 from the subsequent ranking.\nAfter setting aside the general conversational topic, the most dominant thematic topics are as follows:\n\n\n\nOverall Topic Distribution\n\n\n\n1. Dominant Thematic Topics\n\nTopic 2 (13.6%)\nKeywords: human, ai, power, energy, car, years\nThis is the most prominent thematic topic, focusing on human–AI relations, emerging technologies, and long-term trends in energy and transportation. It highlights discussions centered on technological development and future-oriented themes.\nTopic 7 (13.0%)\nKeywords: learn, help, project, learning, software, job\nThis topic captures discourse around learning resources, technical support, project development, and career-related topics. It indicates active participation in educational and professional growth discussions within AI-focused communities.\nTopic 0 (11.8%)\nKeywords: data, apple, ai, science, user, marketing\nThis topic encompasses discussions at the intersection of technology and business, including data science, AI applications, and technology-driven business practices.\n\n\n\n2. Secondary Thematic Topics\n\nTopic 8 (11.3%)\nKeywords: job, jobs, entrepreneur, pay, business, company\nThis topic pertains to employment and entrepreneurship, reflecting user interest in career opportunities, compensation, and business activities.\nTopic 4 (11.0%)\nKeywords: code, python, data, using, language, windows\nThis topic represents programming and technical practice, emphasizing coding, software tools, and computational workflows.\n\n\n\n3. Peripheral Topics\n\nTopic 3 (7.7%)\nKeywords: word, images, water, read, data\nThis topic relates to information extraction, text and image processing, and data analysis.\nTopics 1, 5, 9 (&lt;5% each)\nThese topics include discussions about application development and APIs, community interactions, and conversational agents such as ChatGPT.\n\n\n\n4. Overall Interpretation\n\nAfter filtering out the large general conversational topic (Topic 6), the discourse is led by discussions on future-oriented technology and human-AI relations (Topic 2).\nCareer and learning-focused topics (Topics 7 and 8) remain highly significant, accounting for roughly 24% of the corpus and highlighting a strong user focus on professional development.\nTechnology and business-related discussions (Topics 0, 4) are also central, collectively representing over 22% of the content.\nThis revised distribution reveals that beneath a layer of casual conversation, the community’s core focus is on the future implications of technology, career growth, and practical applications in business and programming."
  },
  {
    "objectID": "NLP_WEB.html#business-question-6-what-are-the-baseline-emotional-patterns-of-discussions-about-ai-and-emerging-technologies",
    "href": "NLP_WEB.html#business-question-6-what-are-the-baseline-emotional-patterns-of-discussions-about-ai-and-emerging-technologies",
    "title": "Natural Language Processing",
    "section": "Business Question 6: What are the baseline emotional patterns of discussions about AI and emerging technologies?",
    "text": "Business Question 6: What are the baseline emotional patterns of discussions about AI and emerging technologies?\nMethod: We applied the VADER sentiment analysis tool to each comment and submission to calculate a compound score, which ranges from -1 (most negative) to +1 (most positive). Scores are then categorized as positive (&gt;=0.05), neutral, or negative (&lt;=-0.05).\nAnalysis of Sentiment Distribution: The stacked bar chart below shows the proportion of comments falling into each sentiment category for the most active subreddits.\n\n\n\nSentiment distribution\n\n\n\nFinding 1: Neutrality is Dominant. Across almost all communities, the vast majority of comments are classified as neutral. This indicates that discussions on technical and scientific topics are often objective, informative, and factual rather than emotionally charged.\nFinding 2: Positive Skew. In most subreddits, the proportion of positive comments is noticeably higher than negative ones. This suggests a generally constructive or optimistic underlying tone, even within objective discussions.\n\nAnalysis of Average Compound Score: The bar chart below visualizes the average compound sentiment score for each subreddit.\n\n\n\ncompound\n\n\n\nFinding 3: Mildly Positive Atmosphere. Consistent with the distribution analysis, the average sentiment score for most subreddits is slightly above zero, confirming a modest but persistent positive inclination. For example, communities like AIforGood and OpenAI show a stronger positive leaning.\nFinding 4: Lack of Strong Negativity. Very few communities exhibit a negative average sentiment, and even those that do are only slightly negative. This reinforces the conclusion that the overall discussion atmosphere is not contentious but rather balanced and leaning towards positive."
  },
  {
    "objectID": "NLP_WEB.html#business-question-7-how-do-external-technological-or-policy-events-disrupt-or-reshape-existing-discussion-patterns-in-online-technology-related-communities",
    "href": "NLP_WEB.html#business-question-7-how-do-external-technological-or-policy-events-disrupt-or-reshape-existing-discussion-patterns-in-online-technology-related-communities",
    "title": "Natural Language Processing",
    "section": "Business Question 7: How do external technological or policy events disrupt or reshape existing discussion patterns in online technology-related communities?",
    "text": "Business Question 7: How do external technological or policy events disrupt or reshape existing discussion patterns in online technology-related communities?\nWe selected a set of representative subreddits and categorized them into four major groups:\nAI/ML: This category includes ChatGPT, OpenAI, ArtificialIntelligence, MachineLearning, GenerativeAI, and AIethics. It focuses on discussions related to artificial intelligence, machine learning, generative AI, and associated ethical considerations.\nProgramming/Data: This group comprises datascience, bigdata, programming, Python, learnprogramming, and CloudComputing, highlighting topics in programming, data science, and technical learning.\nScience/STEM: Covering science, Physics, Engineering, Astronomy, Neuroscience, and MaterialsScience, this category addresses general science and STEM-related topics.\nTech/Future Trends: Including technology, Futurology, TechCulture, Innovation, and FutureTechnology, this category captures discussions about technological trends, innovation, and future-oriented topics.\nEach comment from these subreddits was analyzed using NLTK’s VADER to compute monthly average sentiment trends.\nIn the visualization, the vertical gray dashed lines represent key AI and technology events:\nClaude 2 launch (2023-07-12)\nOpenAI Developer Day (2023-11-06)\nGemini launch (2024-02-15)\nThe EU AI Act (2024-04-17)\nGPT-5 rumors (2024-06-20).\nThese lines serve as reference points to observe sentiment fluctuations around the time of significant events.\n\n\n\nSentiment trend\n\n\nAnalysis of Sentiment Trend: The chart below plots the average monthly sentiment for four distinct categories of subreddits. Key industry and policy events are marked with vertical lines to contextualize the trends.\n\n\n\nSentiment trend\n\n\n\nOverall Stability: The primary finding is that sentiment across all four categories remains remarkably stable over the year, with average scores consistently hovering in the neutral-to-mildly-positive range (0.05 to 0.15). This suggests a mature and steady discussion environment that is not prone to dramatic, long-term shifts in mood.\nEvent-Driven Fluctuations in AI/ML: The AI/ML category (blue line) displays the most sensitivity to external events.\n\nFollowing the Gemini launch (Feb 2024) and the EU AI Act (Apr 2024), this category shows a distinct upward trend, indicating a period of increased optimism and positive discussion.\nThis suggests that major product releases and significant regulatory milestones can temporarily boost positive sentiment within core AI communities.\n\nConsistency in Other Categories: The Programming/Data, Science/STEM, and Tech/Future Trends categories show even less volatility, reinforcing the idea that their discussion tones are less influenced by specific AI-related news cycles.\n\n\nTopic Trend\nWe also analyzed the distribution of the ten topics (discovered in RQ5) over time.\n\n\n\nTopic Trend\n\n\n\nConclusion: As shown in the stacked area chart, the relative prevalence of each topic remains highly consistent throughout the year. There are no major shifts, indicating that the fundamental areas of discussion within these communities are stable and not subject to seasonal or event-driven changes. For example, “informal conversation” (Topic 6) and “human-AI relations” (Topic 2) consistently remain the most dominant topics."
  },
  {
    "objectID": "NLP_WEB.html#business-question-8-how-do-users-shape-topic-emphasis-and-sentiment-dynamics-across-science-technology-and-ai-subreddits",
    "href": "NLP_WEB.html#business-question-8-how-do-users-shape-topic-emphasis-and-sentiment-dynamics-across-science-technology-and-ai-subreddits",
    "title": "Natural Language Processing",
    "section": "Business Question 8: How do users shape topic emphasis and sentiment dynamics across science, technology, and AI subreddits?",
    "text": "Business Question 8: How do users shape topic emphasis and sentiment dynamics across science, technology, and AI subreddits?\nTo explore the semantic characteristics of discussions related to Technology, Science, and AI, word clouds were created to visualize the most frequent and prominent terms within each topic group.\nDiscussion content was classified into four categories using a rule-based approach:\n\nTechnical: Text containing keywords related to model architectures, neural networks, training, or optimization.\nEthical: Text containing keywords related to ethics, bias, regulations, or fairness.\nSocietal: Text containing keywords related to societal impact, education, policy, or employment.\nOther: Text not matching any of the above patterns.\n\nThis approach allows the word clouds to intuitively highlight the main topics and language features within each category, providing a visual understanding of community focus.\n\n\n\nWordCloud\n\n\nAnalysis: The word clouds reveal clear thematic distinctions between the different categories of discussion:\n\nEthical Discussion: Prominent keywords include regulation, responsibility, human, bias, fairness, and moral. This indicates that discourse in this category centers on the governance, accountability, and human-centric implications of AI and technology.\nSocietal Discussion: Dominant words include job, work, company, society, future, and impact. This highlights a focus on the real-world consequences of technology, particularly concerning employment, corporate influence, and long-term social structures.\nTechnical Discussion: Key terms are model, data, training, LLM, neural, and architecture. This demonstrates a clear focus on the mechanics of AI development, including model design, data handling, and the specifics of training large language models.\nOther Discussion: This category is characterized by general or meta-discussion words like removed, know, need, work, and time. It likely captures content related to moderation, general inquiries, or conversations that do not fit neatly into the other three themes."
  },
  {
    "objectID": "report.html#key-recommendations",
    "href": "report.html#key-recommendations",
    "title": "Project Report",
    "section": "Key Recommendations",
    "text": "Key Recommendations\nOur findings suggest several strategic recommendations for engaging with Reddit’s science and technology communities:\n\nAlign with Key Events: Capitalize on the event-driven nature of AI subreddits by timing announcements and content to coincide with major industry milestones.\nTailor Content to the Audience: Differentiate between technical and general-interest communities. Provide in-depth content for niche forums and high-level, concise narratives for broader ones.\nFocus on High-Impact Threads: In large subreddits, strategically engage in viral or high-visibility posts to maximize influence and shape community sentiment.\nLeverage the Constructive Environment: The stable, neutral-to-positive sentiment provides a safe space for organizations to contribute expert insights and educational content.\nUse ML for Triage, Not Automation: While our predictive models have high recall, their precision is limited. Use them to flag content for human review rather than for fully automated moderation.\nSegment Engagement Strategies: Recognize that most discussions are casual. Develop broad, conversational content for the majority, while reserving targeted, technical material for specialized subgroups to improve engagement efficiency."
  },
  {
    "objectID": "report.html#next-steps",
    "href": "report.html#next-steps",
    "title": "Project Report",
    "section": "Next Steps",
    "text": "Next Steps\nFuture work could extend this analysis in several promising directions:\n\nAdvanced Modeling: Improve predictive accuracy by using contextual language embeddings (e.g., BERT), richer metadata, and more sophisticated classifiers like gradient boosting or transformers.\nNuanced Community Detection: Employ hierarchical or density-based clustering to uncover more subtle community structures and integrate these findings into forecasting models.\nLongitudinal and Causal Analysis: Extend the analysis over a longer timeframe to track multi-year evolution and integrate external datasets (e.g., news sentiment, policy timelines) to establish causal links between real-world events and online discourse.\nForecasting Pipelines: Develop a full forecasting pipeline to predict subreddit-level sentiment and activity, enabling proactive communication and engagement strategies."
  },
  {
    "objectID": "EDA_WEB.html#overview",
    "href": "EDA_WEB.html#overview",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "This section presents a comprehensive exploratory data analysis (EDA) of user activity across 46 major AI and technology-focused subreddits from June 2023 to July 2024. By processing a large-scale dataset of over 12 million comments and 800,000 submissions with Spark and Python, we investigate four key business questions. Our analysis uncovers temporal activity patterns, quantifies user engagement and retention, measures attention inequality in discussions, and maps the landscape of cross-community user overlap. These findings provide a foundational understanding of the behavioral dynamics shaping the Reddit AI and technology ecosystem."
  },
  {
    "objectID": "EDA_WEB.html#business-question-1-how-has-community-activity-evolved-across-ai-and-technology-subreddits-over-time",
    "href": "EDA_WEB.html#business-question-1-how-has-community-activity-evolved-across-ai-and-technology-subreddits-over-time",
    "title": "Exploratory Data Analysis",
    "section": "Business Question 1: How has community activity evolved across AI and technology subreddits over time?",
    "text": "Business Question 1: How has community activity evolved across AI and technology subreddits over time?\n\nAnalysis Approach\nTo answer this, we aggregated the total number of posts and comments by subreddit for each month. This allowed us to create a time-series visualization that highlights activity trends, identifies periods of significant growth or decline, and compares the engagement trajectories of different communities. Surges in activity were then contextualized with major AI or technology events.\n\n\nFindings\n\n\n\nMonthly Activity Trends\n\n\n\ntechnology consistently dominates in overall activity, peaking above 300,000 monthly interactions and reflecting broad, sustained user interest.\nChatGPT shows pronounced surges, especially around late 2023 and early 2024, which likely correspond to major product updates and public announcements (e.g., OpenAI DevDay).\nFuturology exhibits a steady upward trend, suggesting growing mainstream interest in future-oriented and AI-related discussions.\nOpenAI experiences sharp but short-lived spikes, consistent with event-driven engagement tied to specific releases or corporate news.\nSmaller communities like MachineLearning and ArtificialInteligence remain relatively stable, indicating a more niche and consistent user base.\n\nOverall, activity patterns reveal that while major AI/tech events drive short-term spikes in specialized communities, broader technology interest maintains a high baseline of engagement throughout the year."
  },
  {
    "objectID": "EDA_WEB.html#business-question-2-which-ai-related-subreddits-demonstrate-the-strongest-user-engagement-and-retention-over-time",
    "href": "EDA_WEB.html#business-question-2-which-ai-related-subreddits-demonstrate-the-strongest-user-engagement-and-retention-over-time",
    "title": "Exploratory Data Analysis",
    "section": "Business Question 2: Which AI-related subreddits demonstrate the strongest user engagement and retention over time?",
    "text": "Business Question 2: Which AI-related subreddits demonstrate the strongest user engagement and retention over time?\n\nAnalysis Approach\nWe used Spark to compute a monthly returning-to-active user ratio for each subreddit. This metric serves as a proxy for user retention, measuring the proportion of a month’s active users who also participated in the previous month. A heatmap was then used to visualize these retention ratios, allowing for easy comparison of which communities maintain consistent user engagement over time.\n\n\nFindings\n\n\n\nUser Retention Heatmap\n\n\n\nNiche communities show sharp fluctuations. Subreddits like Alethics exhibit periods of extremely high retention (ratios near 1.0), suggesting that when relevant topics emerge, nearly all active users are returning participants. However, this engagement is event-driven and not sustained.\nMainstream AI subreddits maintain stable retention. Larger communities like ChatGPT, MachineLearning and OpenAI consistently show retention ratios in the 0.2–0.4 range. This stability reflects a healthier, more durable engagement structure with a continuous flow of content and a steady user base.\nGeneral AI forums demonstrate stronger cohesion. Communities like MachineLearning and OpenAI do not show extreme highs but maintain a persistent core of recurring users, indicating a well-established community identity that encourages return visits even without major events.\n\nIn summary, the heatmap highlights a clear distinction: niche subreddits achieve high short-term engagement but lack consistency, whereas mainstream subreddits sustain steady returning-user activity, suggesting stronger community health and long-term value."
  },
  {
    "objectID": "EDA_WEB.html#business-question-3-how-concentrated-is-attention-within-ai-and-tech-discussions",
    "href": "EDA_WEB.html#business-question-3-how-concentrated-is-attention-within-ai-and-tech-discussions",
    "title": "Exploratory Data Analysis",
    "section": "Business Question 3: How concentrated is attention within AI and tech discussions?",
    "text": "Business Question 3: How concentrated is attention within AI and tech discussions?\n\nAnalysis Approach\nTo measure attention inequality, we calculated the Gini coefficient of comments per post for each subreddit. A Gini coefficient near 1 indicates that a very small number of “viral” posts attract most of the comments, while a value closer to 0 suggests that attention is distributed more evenly across many posts. We visualized these distributions using violin plots and bar charts to compare concentration levels.\n\n\nFindings\n\n\n\nDiscussion Gini Index Violin Plot\n\n\n\n\n\nAverage Gini Index Bar Chart\n\n\n\ntechnology and ChatGPT exhibit the highest attention concentration, with average Gini coefficients approaching 0.90. This “winner-take-most” dynamic is typical of large, news-driven communities where engagement is dominated by a few highly viral posts.\nTechnical communities show lower inequality. Subreddits like MachineLearning and datascience have more moderate Gini values (≈0.70–0.78). This indicates a healthier, more evenly distributed engagement pattern where discussions are spread across a wider range of specialized, topic-focused posts rather than a few viral threads.\nOpenAI occupies a middle ground, with moderate concentration levels but higher month-to-month variability, reflecting its sensitivity to event-driven news cycles.\n\nThese findings reveal a structural divide: general-interest subreddits are prone to viral, top-heavy discussions, while expert-focused communities foster a more equitable distribution of attention across multiple parallel conversations."
  },
  {
    "objectID": "EDA_WEB.html#business-question-4-do-ai-and-technology-subreddits-share-overlapping-user-communities",
    "href": "EDA_WEB.html#business-question-4-do-ai-and-technology-subreddits-share-overlapping-user-communities",
    "title": "Exploratory Data Analysis",
    "section": "Business Question 4: Do AI and technology subreddits share overlapping user communities?",
    "text": "Business Question 4: Do AI and technology subreddits share overlapping user communities?\n\nAnalysis Approach\nWe identified the unique user bases for each subreddit and then computed the pairwise Jaccard similarity to quantify the degree of user overlap between every pair of communities. The resulting similarity matrix was visualized as a heatmap, where warmer colors would indicate a higher percentage of shared users.\n\n\nFindings\n\n\n\nCross-Subreddit User Overlap Heatmap\n\n\n\nOverall user overlap is extremely low. The vast majority of Jaccard similarity scores are close to zero, indicating that the selected AI and technology subreddits attract largely distinct and separate audiences.\nEven closely related communities are siloed. For instance, AI-centric subreddits like ChatGPT, OpenAI, and ArtificialInteligence do not share a significant user base. This suggests that users tend to engage with platform- or topic-specific communities rather than participating broadly across the AI ecosystem.\nThe strong diagonal pattern in the heatmap visually confirms that each subreddit functions as a relatively independent community with minimal cross-pollination of users during the observed period."
  },
  {
    "objectID": "EDA_WEB.html#summary",
    "href": "EDA_WEB.html#summary",
    "title": "Exploratory Data Analysis",
    "section": "Summary",
    "text": "Summary\nThis exploratory analysis reveals several key dynamics of Reddit’s AI and technology ecosystem:\n\nCommunity Activity is Event-Driven: Monthly activity in specialized subreddits like ChatGPT spikes in response to major industry events, while broader forums like technology maintain high, consistent engagement.\nRetention Varies by Community Type: Niche communities experience volatile but intense user retention, whereas larger, mainstream subreddits demonstrate more stable and durable long-term engagement.\nAttention is Highly Concentrated in Large Forums: General-interest tech subreddits exhibit a “winner-take-most” pattern where a few viral posts dominate discussion. In contrast, technical communities foster a more equitable distribution of attention.\nUser Communities are Highly Siloed: There is minimal user overlap between different AI and tech subreddits, indicating that these online spaces operate as distinct communities with specialized audiences rather than an interconnected network."
  },
  {
    "objectID": "NLP_WEB.html#overview",
    "href": "NLP_WEB.html#overview",
    "title": "Natural Language Processing",
    "section": "",
    "text": "This study employs Natural Language Processing (NLP) techniques to investigate discussions related to Technology, Science, and Artificial Intelligence on Reddit. We analyze community discourse across multiple subreddits to identify dominant topics, track sentiment trends over time, and explore thematic differences in ethical, technical, and societal discussions. Methods include Latent Dirichlet Allocation (LDA) for topic modeling, VADER for sentiment analysis, and rule-based text classification to generate word clouds, providing both quantitative and visual insights into the semantic structure and community focus within AI- and technology-related discussions."
  },
  {
    "objectID": "NLP_WEB.html#summary",
    "href": "NLP_WEB.html#summary",
    "title": "Natural Language Processing",
    "section": "Summary",
    "text": "Summary\nThis NLP analysis of Reddit discussions reveals a stable and thematically rich discourse environment:\n\nDominant Topics are Future-Oriented and Practical: After filtering out general chatter, the most significant topics revolve around human-AI relations, career and skill development, and the intersection of technology and business. This indicates a community focused on both the philosophical implications and practical applications of AI.\nSentiment is Consistently Neutral-to-Positive: The vast majority of discussions are objective and informative rather than emotionally charged. A persistent positive skew suggests a generally constructive and optimistic atmosphere across most technology and AI subreddits.\nDiscourse is Resilient to External Events: Despite a volatile year of AI news, both topic distribution and overall sentiment remained remarkably stable. Major product launches or policy decisions caused only minor, short-lived sentiment shifts in highly specialized AI forums, indicating a mature and resilient discussion landscape.\nDiscussions are Thematically Distinct: Users naturally segment conversations into clear categories. Ethical discussions focus on governance and bias, societal discussions on jobs and real-world impact, and technical discussions on the mechanics of AI models, each with its own distinct vocabulary."
  },
  {
    "objectID": "ml.html#business-question-9-can-the-quality-of-reddit-comments-in-science-technology-and-ai-subreddits-be-predicted-from-comment-content-and-basic-behavioral-features",
    "href": "ml.html#business-question-9-can-the-quality-of-reddit-comments-in-science-technology-and-ai-subreddits-be-predicted-from-comment-content-and-basic-behavioral-features",
    "title": "Machine Learning",
    "section": "Business Question 9: Can the Quality of Reddit Comments in Science, Technology, and AI Subreddits Be Predicted from comment content and basic behavioral features?",
    "text": "Business Question 9: Can the Quality of Reddit Comments in Science, Technology, and AI Subreddits Be Predicted from comment content and basic behavioral features?\nThe Reddit score is calculated using the platform’s voting system and is defined as:\nscore = upvotes − downvotes\nThis value reflects community evaluation of how useful or high-quality a comment is.\nTo explore how well we can predict comment quality under different definitions, we designed three classification experiments:\n\nExperiment 1 – Predicting general high-quality comments\n\nPositive class: score ≥ 6\n\nRepresents comments with moderate positive engagement.\n\nExperiment 2 – Predicting highly popular high-quality comments\n\nPositive class: score ≥ 20\n\nTargets comments that achieved strong community resonance.\n\nExperiment 3 – Predicting low-quality comments\n\nPositive class: score &lt; 0\n\nA reverse-classification setup focusing on comments evaluated negatively by the community.\n\n\nClass weighting applied to address imbalance (weightCol used in LogisticRegression).\nTrain/test splits performed in code (80/20).\nAcross all three experiments, we trained Logistic Regression models using both TF-IDF text features and behavioral features such as comment length, URL presence, posting hour, and day of week.\nModel performance was evaluated using standard classification metrics including Accuracy, Precision, Recall, F1-score, and AUC.\n\nModel performance on Experiment 1\n\n\n\nMetric\nAccuracy\nPrecision\nRecall\nF1-score\nAUC\n\n\n\n\nValue\n0.5047\n0.2227\n0.7064\n0.3386\n0.6257\n\n\n\n\n  \n\nOverall, the model exhibits a clear bias in identifying high-quality comments. On one hand, it successfully detects 318,706 high-quality comments (true positives), demonstrating strong recall; on the other hand, it misclassifies 1,112,372 low-quality comments as high-quality (false positives), indicating substantial difficulty in distinguishing positive from negative samples. This “high recall, low precision” pattern means the model is effective at capturing potentially valuable content but generates a large number of false alarms, making it unsuitable for fully automated applications requiring high precision.\nIn terms of overall performance, the ROC curve shows AUC = 0.626, only slightly better than random guessing, indicating limited discriminative ability. Further inspection of the Precision–Recall curve reveals that, due to the low precision, simply adjusting thresholds is unlikely to significantly improve precision, reflecting a performance ceiling with the current feature representation. The main reason is that the current HashingTF text representation fails to effectively capture semantic information, making it difficult to distinguish high-value comments from regular ones.\n\n\nModel performance on Experiment 2\n\n\n\nMetric\nAccuracy\nPrecision\nRecall\nF1-score\nAUC\n\n\n\n\nLogisticRegression\n0.575\n0.069\n0.611\n0.125\n0.636\n\n\n\n\n  \n\nThe model identifies a portion of high-quality comments (76,072 true positives) but misclassifies a substantial number of low-quality comments as high-quality (1,020,158 false positives). In the original dataset, high-quality comments constitute only a small fraction of the total samples, reflecting a significant class imbalance. Although we applied class weighting in Logistic Regression to partially mitigate this imbalance, the model still exhibits extremely low precision (0.069) despite moderate recall (0.611).\nThe ROC curve shows AUC = 0.636, indicating that the model has modest discriminative ability — it performs better than random but is far from optimal. The Precision–Recall (PR) curve further highlights the issue: while recall is reasonable, precision remains extremely low, and adjusting the classification threshold is unlikely to improve it substantially. This demonstrates that the model tends to predict a large number of samples as positive (high-quality), resulting in many false positives.\n\n\nModel performance on Experiment 3\n\n\n\nAccuracy\nPrecision\nRecall\nF1-score\nAUC\n\n\n\n\n0.605\n0.067\n0.634\n0.121\n0.666\n\n\n\n\n  \n\nThe model identifies a portion of low-quality comments (68,049 true positives) but misclassifies a substantial number of high-quality comments as low-quality (953,913 false positives). In the original dataset, low-quality comments constitute only a small fraction of the total samples, reflecting a significant class imbalance. Although we applied class weighting in Logistic Regression to partially mitigate this imbalance, the model still exhibits extremely low precision (0.067) despite moderate recall (0.634).\nThe ROC curve shows AUC = 0.666, indicating that the model has modest discriminative ability — it performs better than random but is far from optimal. The Precision–Recall (PR) curve further highlights the issue: while recall is reasonable, precision remains extremely low, and adjusting the classification threshold is unlikely to improve it substantially. This demonstrates that the model tends to predict a large number of samples as positive (low-quality), resulting in many false positives.\nThis “high recall, very low precision” behavior suggests that the model may be useful for flagging potential low-quality comments for further review but is not suitable for fully automated high-precision applications. Compared with Experiment 1 (general high-quality comments), the precision is even lower, indicating that predicting low-quality comments is particularly challenging due to their rarity and the limitations of the current text and behavioral features.\nSummary and Comparison of Experiments:\nAcross the three experiments, Logistic Regression models showed the following patterns:\n\nExperiment 1 (general high-quality comments): High recall (≈71%) but low precision (≈22%), indicating the model can identify most high-quality comments but produces many false positives.\n\nExperiment 2 (highly popular high-quality comments): Even lower precision (≈7%) with moderate recall (≈63%), reflecting the difficulty of predicting rare highly popular comments despite applying class weighting.\n\nExperiment 3 (low-quality comments): Low precision (≈7%) with moderate recall (≈61%), showing that identifying low-quality comments is also challenging but feasible for flagging purposes.\n\nConclusion:\nLogistic Regression can partially predict comment quality using text and behavioral features. The models are useful for flagging candidate comments (high recall), but due to low precision, they are not suitable for fully automated decisions. Predicting extreme categories (highly popular or low-quality comments) is more difficult due to class imbalance and feature limitations.\nTherefore, key directions for improving model performance are:\n\nUse stronger semantic embeddings (e.g., BERT, Sentence-BERT) to better capture contextual and semantic information in comments.\nApply more powerful classifiers (e.g., Gradient Boosting, XGBoost, LightGBM) and incorporate richer metadata.\nFurther optimize threshold strategies and feature engineering based on task requirements."
  },
  {
    "objectID": "ml.html#business-question-10-can-distinct-discussion-communities-be-identified-within-technology-related-subreddits-based-on-patterns-of-language-use",
    "href": "ml.html#business-question-10-can-distinct-discussion-communities-be-identified-within-technology-related-subreddits-based-on-patterns-of-language-use",
    "title": "Machine Learning",
    "section": "Business Question 10: Can distinct discussion communities be identified within technology-related subreddits based on patterns of language use?",
    "text": "Business Question 10: Can distinct discussion communities be identified within technology-related subreddits based on patterns of language use?\nIn this analysis, we aim to explore whether technology-related subreddits exhibit distinct discussion communities that can be characterized by their language patterns. By examining the textual content of subreddit submissions, we investigate the extent to which subreddits cluster together based on shared terminology, phrasing, and communication styles. Identifying these communities can provide insights into topic specialization, user engagement, and the structure of discourse across different forums. This understanding can also inform strategies for content moderation, recommendation systems, and targeted community engagement.\nWe randomly selected 50,000 subreddit submissions and applied K-Means clustering to their TF-IDF features. The goal was to identify groups of subreddits that share similar textual content and language use. The elbow method was used to determine the optimal number of clusters (K).\n\nCluster artifacts and model saved in code/ml/models/kmeans_k13.\nCluster analysis summary: data/csv/ML2_cluster_analysis.csv.\nElbow chart for K selection: data/plots/ML2_elbow_method.png.\n\n\nAfter applying the elbow method to evaluate the optimal number of clusters, and balancing within-cluster cohesion against between-cluster separation, we ultimately selected 13 clusters. This choice preserves thematic consistency within each cluster while ensuring sufficient distinction between clusters, thereby capturing meaningful differences in language use across technology-related subreddits.\nThis is the cluster visualization：\nThis cluster visualization shows that some clusters are fairly well-separated, while others are tightly overlapping. \nCluster Sizes and Distribution\nCluster sizes vary significantly, from small technical or code-specific clusters (size 6–185) to very large community discussion clusters (size 4,989–43,558).\nLargest clusters:\nCluster 10 (43,558) – AI community high-frequency discussions, including ChatGPT-related topics.\nCluster 8 (4,989) – Natural-language conversational discussions, reflecting informal user interactions.\nMedium clusters: Clusters 3, 6, and 11 (185–511) capture AI-related code/project discussions, AI comment interactions, and Python tutorials.\nSmall clusters: Clusters 0–5, 7, 9, 12 (6–301) are focused on specific programming tasks, code snippets, game logic, front-end layout, or grid/table operations.\n\n\n\n\n\n\n\n\n\nCluster ID\nSize\nTop Terms\nCategory Tendency\n\n\n\n\n0\n14\npaused, playing, def, import, printstrfplaypause, const, new, return, else\nAudio/video player related code snippets / scripting functionality\n\n\n1\n17\nreturn, x, resize, div, px, int, y, tilesize, public\nFront-end web layout / GUI related code\n\n\n2\n43\nreturn, import, def, guess, code, data, px, value, div\nPython programming basics / data processing / small program logic\n\n\n3\n185\nai, xb, code, import, new, data, x, return, use\nAI-related code or project implementation / algorithm development\n\n\n4\n13\nxb, false, player, temparray, return, gamepass, manufacturer, imgnull, true\nGame development or player logic / small program functionality\n\n\n5\n6\nreturn, import, public, int, new, cell, def, class, grid\nGrid or table processing / object-oriented basic code\n\n\n6\n511\nai, like, im, data, use, time, get, code, new\nAI community comments / user interaction related text\n\n\n7\n99\nimport, return, def, div, left, right, else, data, code\nFront-end layout and function logic / web page scripting\n\n\n8\n4989\nim, like, time, ive, know, get, work, ai, dont\nCommunity natural-language discussions / user comments / social interaction\n\n\n9\n162\ncode, import, xb, im, return, new, file, like, def\nProgramming discussion / file operations / small scripts\n\n\n10\n43558\nremoved, im, ai, like, chatgpt, gpt, new, use, get\nAI community high-frequency discussions / ChatGPT-related topics\n\n\n11\n301\ncode, im, def, xb, import, like, return, python, x\nProgramming tutorials / Python code examples / scripts\n\n\n12\n102\ntime, like, ai, xb, people, one, get, new, first\nAI community comments / user time and opinion expression\n\n\n\nCluster Content Summary\n\n\n\n\n\n\n\n\n\nCategory\nCluster IDs\nPercentage\nDescription\n\n\n\n\nNatural-Language / General Discussion\n10, 8, 6, 12\n98%\nLarge-scale conversational content, general discussions about AI, user opinions, and everyday language.\n\n\nProgramming / Technical Content\n0, 1, 2, 3, 5, 7, 9, 11\n2%\nCode snippets, debugging, Python scripts, front-end layouts, data-processing code, and AI project implementation.\n\n\n\nBased on K-Means clustering of 50,000 randomly selected subreddit submissions, we categorized 13 clusters into two main content domains: Natural-Language / General Discussion and Programming / Technical Content.\nNatural-Language / General Discussion (Clusters 6, 8, 10, 12 – 98% of submissions)\nCluster 10 (43,558 submissions): High-frequency AI discussions, including ChatGPT, AI concepts, and moderation-related content (‘removed’). Represents the largest portion of general AI conversations.\nCluster 8 (4,989 submissions): Conversational discussions with informal language (‘im’, ‘like’, ‘time’), reflecting community interactions and casual exchanges.\nCluster 6 (511 submissions): AI-related comments with a mix of technical terms and user interactions (‘ai’, ‘code’, ‘use’, ‘time’), bridging casual discussion and technical engagement.\nCluster 12 (102 submissions): Smaller cluster capturing user opinions, timing, and interaction patterns in AI-related discussions.\nInsight: These clusters dominate Reddit AI conversations, reflecting large-scale user engagement, opinion sharing, and general discussion.\nProgramming / Technical Content (Clusters 0, 1, 2, 3, 5, 7, 9, 11 – 2% of submissions)\nClusters 0, 1, 2, 5, 7, 9, 11: Focus on coding examples, debugging, front-end layouts, and small programming projects. Examples include Python basics, grid/table processing, and front-end scripts.\nCluster 3 (185 submissions): AI-related project implementation and algorithm development, combining technical code with problem-solving content.\nInsight: These clusters are smaller in size but highly specialized, capturing programming-focused discussions and technical knowledge sharing.\nThe clustering effectively separates high-volume conversational discussions from smaller, specialized technical content.\nLarge clusters (Natural-Language) reflect broad engagement and informal community interactions.\nSmall clusters (Technical Content) capture targeted programming topics and code-oriented tasks.\nThese cluster distinctions provide a foundation for feature engineering in predictive models, sentiment analysis, or engagement forecasting, allowing models to treat conversational and technical clusters differently."
  },
  {
    "objectID": "nlp.html#business-question-5-what-are-the-dominant-topics-and-trends-within-fast-growing-technology-related-subreddits",
    "href": "nlp.html#business-question-5-what-are-the-dominant-topics-and-trends-within-fast-growing-technology-related-subreddits",
    "title": "Natural Language Processing",
    "section": "Business Question 5: What are the dominant topics and trends within fast-growing technology-related subreddits?",
    "text": "Business Question 5: What are the dominant topics and trends within fast-growing technology-related subreddits?\nAs shown in the figure, the Latent Dirichlet Allocation (LDA) model identifies ten distinct topics from the corpus, each represented by its most influential keywords. These keywords provide an interpretable summary of the semantic focus of each discovered topic.\nTopic 0 is characterized by keywords such as data, apple, ai, science, user, and marketing, suggesting that this topic centers on discussions related to data science, artificial intelligence, and technology-driven business practices.\nTopic 1 includes terms such as karma, comment, subreddit, message, and questions, indicating that it reflects conversations about community interactions, platform moderation, and posting behaviors within online forums such as Reddit.\nTopic 2 is defined by words like human, ai, power, energy, car, and years, representing discourse around human–AI relations, emerging technologies, and long-term trends in energy and transportation.\nTopic 3 contains keywords including word, images, water, read, and data, pointing to content associated with information extraction, text and image processing, and data-driven analysis.\nTopic 4 focuses on terms such as code, python, data, using, language, and windows, clearly corresponding to programming-related discussions involving software tools, coding practices, and computational workflows.\nTopic 5 includes reddit, app, api, change, party, commercial, and pricing, which collectively suggest themes related to application development, API usage, and commercial product or platform changes.\nTopic 6 is composed of more conversational keywords such as something, never, someone, bad, lol, and yeah, indicating informal, colloquial exchanges or personal expressions within the corpus.\nTopic 7 features terms like learn, help, project, learning, software, and job, pointing to discussions focused on learning resources, technical support, project development, and career-oriented themes.\nTopic 8 is defined by job, jobs, entrepreneur, pay, business, and company, representing topics related to employment, entrepreneurship, compensation, and broader business activities.\nTopic 9 includes keywords such as chatgpt, bot, prompt, conversation, post, and reply, indicating discourse involving conversational agents, prompt design, and user–system interactions.\nOverall, these topics illustrate the LDA model’s ability to uncover coherent thematic structures within the dataset and to organize large volumes of text into interpretable clusters.\n\n\n\nTopic keywords\n\n\n\nOverall Topic Distribution\nAs shown in the pie chart, the Latent Dirichlet Allocation (LDA) model identifies ten distinct topics. Before ranking them, it is crucial to address Topic 6.\nA Note on Topic 6 (General Conversational Topic): Topic 6 (22.4%), with keywords like something, never, someone, bad, lol, yeah, represents a “background” or “general conversational” topic. It captures common, low-specificity words and conversational filler that are prevalent across the entire dataset but do not form a coherent semantic theme. The emergence of such a topic is a common and expected artifact of LDA. For the purpose of identifying the most significant thematic discussions, we will exclude Topic 6 from the subsequent ranking.\nAfter setting aside the general conversational topic, the most dominant thematic topics are as follows:\n\n\n\nOverall Topic Distribution\n\n\n\n1. Dominant Thematic Topics\n\nTopic 2 (13.6%)\nKeywords: human, ai, power, energy, car, years\nThis is the most prominent thematic topic, focusing on human–AI relations, emerging technologies, and long-term trends in energy and transportation. It highlights discussions centered on technological development and future-oriented themes.\nTopic 7 (13.0%)\nKeywords: learn, help, project, learning, software, job\nThis topic captures discourse around learning resources, technical support, project development, and career-related topics. It indicates active participation in educational and professional growth discussions within AI-focused communities.\nTopic 0 (11.8%)\nKeywords: data, apple, ai, science, user, marketing\nThis topic encompasses discussions at the intersection of technology and business, including data science, AI applications, and technology-driven business practices.\n\n\n\n2. Secondary Thematic Topics\n\nTopic 8 (11.3%)\nKeywords: job, jobs, entrepreneur, pay, business, company\nThis topic pertains to employment and entrepreneurship, reflecting user interest in career opportunities, compensation, and business activities.\nTopic 4 (11.0%)\nKeywords: code, python, data, using, language, windows\nThis topic represents programming and technical practice, emphasizing coding, software tools, and computational workflows.\n\n\n\n3. Peripheral Topics\n\nTopic 3 (7.7%)\nKeywords: word, images, water, read, data\nThis topic relates to information extraction, text and image processing, and data analysis.\nTopics 1, 5, 9 (&lt;5% each)\nThese topics include discussions about application development and APIs, community interactions, and conversational agents such as ChatGPT.\n\n\n\n4. Overall Interpretation\n\nAfter filtering out the large general conversational topic (Topic 6), the discourse is led by discussions on future-oriented technology and human-AI relations (Topic 2).\nCareer and learning-focused topics (Topics 7 and 8) remain highly significant, accounting for roughly 24% of the corpus and highlighting a strong user focus on professional development.\nTechnology and business-related discussions (Topics 0, 4) are also central, collectively representing over 22% of the content.\nThis revised distribution reveals that beneath a layer of casual conversation, the community’s core focus is on the future implications of technology, career growth, and practical applications in business and programming."
  },
  {
    "objectID": "nlp.html#business-question-6-what-are-the-baseline-emotional-patterns-of-discussions-about-ai-and-emerging-technologies",
    "href": "nlp.html#business-question-6-what-are-the-baseline-emotional-patterns-of-discussions-about-ai-and-emerging-technologies",
    "title": "Natural Language Processing",
    "section": "Business Question 6: What are the baseline emotional patterns of discussions about AI and emerging technologies?",
    "text": "Business Question 6: What are the baseline emotional patterns of discussions about AI and emerging technologies?\nMethod: We applied the VADER sentiment analysis tool to each comment and submission to calculate a compound score, which ranges from -1 (most negative) to +1 (most positive). Scores are then categorized as positive (&gt;=0.05), neutral, or negative (&lt;=-0.05).\nAnalysis of Sentiment Distribution: The stacked bar chart below shows the proportion of comments falling into each sentiment category for the most active subreddits.\n\n\n\nSentiment distribution\n\n\n\nFinding 1: Neutrality is Dominant. Across almost all communities, the vast majority of comments are classified as neutral. This indicates that discussions on technical and scientific topics are often objective, informative, and factual rather than emotionally charged.\nFinding 2: Positive Skew. In most subreddits, the proportion of positive comments is noticeably higher than negative ones. This suggests a generally constructive or optimistic underlying tone, even within objective discussions.\n\nAnalysis of Average Compound Score: The bar chart below visualizes the average compound sentiment score for each subreddit.\n\n\n\ncompound\n\n\n\nFinding 3: Mildly Positive Atmosphere. Consistent with the distribution analysis, the average sentiment score for most subreddits is slightly above zero, confirming a modest but persistent positive inclination. For example, communities like AIforGood and OpenAI show a stronger positive leaning.\nFinding 4: Lack of Strong Negativity. Very few communities exhibit a negative average sentiment, and even those that do are only slightly negative. This reinforces the conclusion that the overall discussion atmosphere is not contentious but rather balanced and leaning towards positive."
  },
  {
    "objectID": "nlp.html#business-question-7-how-do-external-technological-or-policy-events-disrupt-or-reshape-existing-discussion-patterns-in-online-technology-related-communities",
    "href": "nlp.html#business-question-7-how-do-external-technological-or-policy-events-disrupt-or-reshape-existing-discussion-patterns-in-online-technology-related-communities",
    "title": "Natural Language Processing",
    "section": "Business Question 7: How do external technological or policy events disrupt or reshape existing discussion patterns in online technology-related communities?",
    "text": "Business Question 7: How do external technological or policy events disrupt or reshape existing discussion patterns in online technology-related communities?\nWe selected a set of representative subreddits and categorized them into four major groups:\nAI/ML: This category includes ChatGPT, OpenAI, ArtificialIntelligence, MachineLearning, GenerativeAI, and AIethics. It focuses on discussions related to artificial intelligence, machine learning, generative AI, and associated ethical considerations.\nProgramming/Data: This group comprises datascience, bigdata, programming, Python, learnprogramming, and CloudComputing, highlighting topics in programming, data science, and technical learning.\nScience/STEM: Covering science, Physics, Engineering, Astronomy, Neuroscience, and MaterialsScience, this category addresses general science and STEM-related topics.\nTech/Future Trends: Including technology, Futurology, TechCulture, Innovation, and FutureTechnology, this category captures discussions about technological trends, innovation, and future-oriented topics.\nEach comment from these subreddits was analyzed using NLTK’s VADER to compute monthly average sentiment trends.\nIn the visualization, the vertical gray dashed lines represent key AI and technology events:\nClaude 2 launch (2023-07-12)\nOpenAI Developer Day (2023-11-06)\nGemini launch (2024-02-15)\nThe EU AI Act (2024-04-17)\nGPT-5 rumors (2024-06-20).\nThese lines serve as reference points to observe sentiment fluctuations around the time of significant events.\n\n\n\nSentiment trend\n\n\nAnalysis of Sentiment Trend: The chart below plots the average monthly sentiment for four distinct categories of subreddits. Key industry and policy events are marked with vertical lines to contextualize the trends.\n\n\n\nSentiment trend\n\n\n\nOverall Stability: The primary finding is that sentiment across all four categories remains remarkably stable over the year, with average scores consistently hovering in the neutral-to-mildly-positive range (0.05 to 0.15). This suggests a mature and steady discussion environment that is not prone to dramatic, long-term shifts in mood.\nEvent-Driven Fluctuations in AI/ML: The AI/ML category (blue line) displays the most sensitivity to external events.\n\nFollowing the Gemini launch (Feb 2024) and the EU AI Act (Apr 2024), this category shows a distinct upward trend, indicating a period of increased optimism and positive discussion.\nThis suggests that major product releases and significant regulatory milestones can temporarily boost positive sentiment within core AI communities.\n\nConsistency in Other Categories: The Programming/Data, Science/STEM, and Tech/Future Trends categories show even less volatility, reinforcing the idea that their discussion tones are less influenced by specific AI-related news cycles.\n\n\nTopic Trend\nWe also analyzed the distribution of the ten topics (discovered in RQ5) over time.\n\n\n\nTopic Trend\n\n\n\nConclusion: As shown in the stacked area chart, the relative prevalence of each topic remains highly consistent throughout the year. There are no major shifts, indicating that the fundamental areas of discussion within these communities are stable and not subject to seasonal or event-driven changes. For example, “informal conversation” (Topic 6) and “human-AI relations” (Topic 2) consistently remain the most dominant topics."
  },
  {
    "objectID": "nlp.html#business-question-8-how-do-users-shape-topic-emphasis-and-sentiment-dynamics-across-science-technology-and-ai-subreddits",
    "href": "nlp.html#business-question-8-how-do-users-shape-topic-emphasis-and-sentiment-dynamics-across-science-technology-and-ai-subreddits",
    "title": "Natural Language Processing",
    "section": "Business Question 8: How do users shape topic emphasis and sentiment dynamics across science, technology, and AI subreddits?",
    "text": "Business Question 8: How do users shape topic emphasis and sentiment dynamics across science, technology, and AI subreddits?\nTo explore the semantic characteristics of discussions related to Technology, Science, and AI, word clouds were created to visualize the most frequent and prominent terms within each topic group.\nDiscussion content was classified into four categories using a rule-based approach:\n\nTechnical: Text containing keywords related to model architectures, neural networks, training, or optimization.\nEthical: Text containing keywords related to ethics, bias, regulations, or fairness.\nSocietal: Text containing keywords related to societal impact, education, policy, or employment.\nOther: Text not matching any of the above patterns.\n\nThis approach allows the word clouds to intuitively highlight the main topics and language features within each category, providing a visual understanding of community focus.\n\n\n\nWordCloud\n\n\nAnalysis: The word clouds reveal clear thematic distinctions between the different categories of discussion:\n\nEthical Discussion: Prominent keywords include regulation, responsibility, human, bias, fairness, and moral. This indicates that discourse in this category centers on the governance, accountability, and human-centric implications of AI and technology.\nSocietal Discussion: Dominant words include job, work, company, society, future, and impact. This highlights a focus on the real-world consequences of technology, particularly concerning employment, corporate influence, and long-term social structures.\nTechnical Discussion: Key terms are model, data, training, LLM, neural, and architecture. This demonstrates a clear focus on the mechanics of AI development, including model design, data handling, and the specifics of training large language models.\nOther Discussion: This category is characterized by general or meta-discussion words like removed, know, need, work, and time. It likely captures content related to moderation, general inquiries, or conversations that do not fit neatly into the other three themes."
  },
  {
    "objectID": "eda.html#business-question-1-how-has-community-activity-evolved-across-ai-and-technology-subreddits-over-time",
    "href": "eda.html#business-question-1-how-has-community-activity-evolved-across-ai-and-technology-subreddits-over-time",
    "title": "Exploratory Data Analysis",
    "section": "Business Question 1: How has community activity evolved across AI and technology subreddits over time?",
    "text": "Business Question 1: How has community activity evolved across AI and technology subreddits over time?\n\nAnalysis Approach\nTo answer this, we aggregated the total number of posts and comments by subreddit for each month. This allowed us to create a time-series visualization that highlights activity trends, identifies periods of significant growth or decline, and compares the engagement trajectories of different communities. Surges in activity were then contextualized with major AI or technology events.\n\n\nFindings\n\n\n\nMonthly Activity Trends\n\n\n\ntechnology consistently dominates in overall activity, peaking above 300,000 monthly interactions and reflecting broad, sustained user interest.\nChatGPT shows pronounced surges, especially around late 2023 and early 2024, which likely correspond to major product updates and public announcements (e.g., OpenAI DevDay).\nFuturology exhibits a steady upward trend, suggesting growing mainstream interest in future-oriented and AI-related discussions.\nOpenAI experiences sharp but short-lived spikes, consistent with event-driven engagement tied to specific releases or corporate news.\nSmaller communities like MachineLearning and ArtificialInteligence remain relatively stable, indicating a more niche and consistent user base.\n\nOverall, activity patterns reveal that while major AI/tech events drive short-term spikes in specialized communities, broader technology interest maintains a high baseline of engagement throughout the year."
  },
  {
    "objectID": "eda.html#business-question-2-which-ai-related-subreddits-demonstrate-the-strongest-user-engagement-and-retention-over-time",
    "href": "eda.html#business-question-2-which-ai-related-subreddits-demonstrate-the-strongest-user-engagement-and-retention-over-time",
    "title": "Exploratory Data Analysis",
    "section": "Business Question 2: Which AI-related subreddits demonstrate the strongest user engagement and retention over time?",
    "text": "Business Question 2: Which AI-related subreddits demonstrate the strongest user engagement and retention over time?\n\nAnalysis Approach\nWe used Spark to compute a monthly returning-to-active user ratio for each subreddit. This metric serves as a proxy for user retention, measuring the proportion of a month’s active users who also participated in the previous month. A heatmap was then used to visualize these retention ratios, allowing for easy comparison of which communities maintain consistent user engagement over time.\n\n\nFindings\n\n\n\nUser Retention Heatmap\n\n\n\nNiche communities show sharp fluctuations. Subreddits like Alethics exhibit periods of extremely high retention (ratios near 1.0), suggesting that when relevant topics emerge, nearly all active users are returning participants. However, this engagement is event-driven and not sustained.\nMainstream AI subreddits maintain stable retention. Larger communities like ChatGPT, MachineLearning and OpenAI consistently show retention ratios in the 0.2–0.4 range. This stability reflects a healthier, more durable engagement structure with a continuous flow of content and a steady user base.\nGeneral AI forums demonstrate stronger cohesion. Communities like MachineLearning and OpenAI do not show extreme highs but maintain a persistent core of recurring users, indicating a well-established community identity that encourages return visits even without major events.\n\nIn summary, the heatmap highlights a clear distinction: niche subreddits achieve high short-term engagement but lack consistency, whereas mainstream subreddits sustain steady returning-user activity, suggesting stronger community health and long-term value."
  },
  {
    "objectID": "eda.html#business-question-3-how-concentrated-is-attention-within-ai-and-tech-discussions",
    "href": "eda.html#business-question-3-how-concentrated-is-attention-within-ai-and-tech-discussions",
    "title": "Exploratory Data Analysis",
    "section": "Business Question 3: How concentrated is attention within AI and tech discussions?",
    "text": "Business Question 3: How concentrated is attention within AI and tech discussions?\n\nAnalysis Approach\nTo measure attention inequality, we calculated the Gini coefficient of comments per post for each subreddit. A Gini coefficient near 1 indicates that a very small number of “viral” posts attract most of the comments, while a value closer to 0 suggests that attention is distributed more evenly across many posts. We visualized these distributions using violin plots and bar charts to compare concentration levels.\n\n\nFindings\n\n\n\nDiscussion Gini Index Violin Plot\n\n\n\n\n\nAverage Gini Index Bar Chart\n\n\n\ntechnology and ChatGPT exhibit the highest attention concentration, with average Gini coefficients approaching 0.90. This “winner-take-most” dynamic is typical of large, news-driven communities where engagement is dominated by a few highly viral posts.\nTechnical communities show lower inequality. Subreddits like MachineLearning and datascience have more moderate Gini values (≈0.70–0.78). This indicates a healthier, more evenly distributed engagement pattern where discussions are spread across a wider range of specialized, topic-focused posts rather than a few viral threads.\nOpenAI occupies a middle ground, with moderate concentration levels but higher month-to-month variability, reflecting its sensitivity to event-driven news cycles.\n\nThese findings reveal a structural divide: general-interest subreddits are prone to viral, top-heavy discussions, while expert-focused communities foster a more equitable distribution of attention across multiple parallel conversations."
  },
  {
    "objectID": "eda.html#business-question-4-do-ai-and-technology-subreddits-share-overlapping-user-communities",
    "href": "eda.html#business-question-4-do-ai-and-technology-subreddits-share-overlapping-user-communities",
    "title": "Exploratory Data Analysis",
    "section": "Business Question 4: Do AI and technology subreddits share overlapping user communities?",
    "text": "Business Question 4: Do AI and technology subreddits share overlapping user communities?\n\nAnalysis Approach\nWe identified the unique user bases for each subreddit and then computed the pairwise Jaccard similarity to quantify the degree of user overlap between every pair of communities. The resulting similarity matrix was visualized as a heatmap, where warmer colors would indicate a higher percentage of shared users.\n\n\nFindings\n\n\n\nCross-Subreddit User Overlap Heatmap\n\n\n\nOverall user overlap is extremely low. The vast majority of Jaccard similarity scores are close to zero, indicating that the selected AI and technology subreddits attract largely distinct and separate audiences.\nEven closely related communities are siloed. For instance, AI-centric subreddits like ChatGPT, OpenAI, and ArtificialInteligence do not share a significant user base. This suggests that users tend to engage with platform- or topic-specific communities rather than participating broadly across the AI ecosystem.\nThe strong diagonal pattern in the heatmap visually confirms that each subreddit functions as a relatively independent community with minimal cross-pollination of users during the observed period."
  },
  {
    "objectID": "eda.html#dataset-summary",
    "href": "eda.html#dataset-summary",
    "title": "Exploratory Data Analysis",
    "section": "Dataset Summary",
    "text": "Dataset Summary\nThis project analyzes a large-scale Reddit dataset covering user activity from June 2023 to July 2024 across 46 unique subreddits, enabling a comprehensive examination of engagement patterns and community dynamics.\nThe dataset’s overall scope is detailed in Table 1. It comprises over 12.5 million comments and 831,000 submissions, providing a rich foundation for analyzing user-generated content and discussion patterns.\nDataset Summary by Data Type\n\n\n\n\n\n\n\n\n\n\nData Type\nTotal Rows\nSize (GB)\nDate Range Start\nDate Range End\n\n\n\n\ncomments\n12,561,291\n12.56\n2023-06-01\n2024-07-31\n\n\nsubmissions\n831,021\n0.83\n2023-06-01\n2024-07-31\n\n\n\nAmong the 46 communities, activity is highly concentrated in a few key subreddits. The top five, measured by the total number of comments and submissions, are:\n\ntechnology — 3,265,248 total rows\n\nChatGPT — 1,894,755 total rows\n\nscience — 1,051,336 total rows\n\ncscareerquestions — 974,990 total rows\n\nFuturology — 914,347 total rows\n\nTo facilitate temporal analysis, this raw data was aggregated into monthly activity counts. Table 2 provides a sample of this structured data, which is used to explore activity trends in Business Question 1.\nSample of Monthly Activity Data\n\n\n\n\n\n\n\n\n\n\nsubreddit\nmonth\nposts\ncomments\ntotal_activity\n\n\n\n\nArtificialInteligence\n2023-06-01\n1900\n11962\n13862\n\n\nArtificialInteligence\n2023-07-01\n1829\n12078\n13907\n\n\nArtificialInteligence\n2023-08-01\n1759\n9922\n11681\n\n\nChatGPT\n2023-06-01\n11357\n139633\n150990\n\n\nChatGPT\n2023-07-01\n10597\n142224\n152821\n\n\nChatGPT\n2023-08-01\n10431\n131996\n142427"
  },
  {
    "objectID": "eda.html#business-question-1",
    "href": "eda.html#business-question-1",
    "title": "Exploratory Data Analysis",
    "section": "Business Question 1",
    "text": "Business Question 1\n\nHow has community activity evolved across AI and technology subreddits over time?\n\n\nAnalysis Approach\nTo answer this, we aggregated the total number of posts and comments by subreddit for each month. This allowed us to create a time-series visualization that highlights activity trends, identifies periods of significant growth or decline, and compares the engagement trajectories of different communities. Surges in activity were then contextualized with major AI or technology events.\n\n\nFindings\n\n\n\nMonthly Activity Trends\n\n\n\ntechnology consistently dominates in overall activity, peaking above 300,000 monthly interactions and reflecting broad, sustained user interest.\nChatGPT shows pronounced surges, especially around late 2023 and early 2024, which likely correspond to major product updates and public announcements (e.g., OpenAI DevDay).\nFuturology exhibits a steady upward trend, suggesting growing mainstream interest in future-oriented and AI-related discussions.\nOpenAI experiences sharp but short-lived spikes, consistent with event-driven engagement tied to specific releases or corporate news.\nSmaller communities like MachineLearning and ArtificialInteligence remain relatively stable, indicating a more niche and consistent user base.\n\nOverall, activity patterns reveal that while major AI/tech events drive short-term spikes in specialized communities, broader technology interest maintains a high baseline of engagement throughout the year."
  },
  {
    "objectID": "eda.html#business-question-2",
    "href": "eda.html#business-question-2",
    "title": "Exploratory Data Analysis",
    "section": "Business Question 2",
    "text": "Business Question 2\n\nWhich AI-related subreddits demonstrate the strongest user engagement and retention over time?\n\n\nAnalysis Approach\nWe used Spark to compute a monthly returning-to-active user ratio for each subreddit. This metric serves as a proxy for user retention, measuring the proportion of a month’s active users who also participated in the previous month. A heatmap was then used to visualize these retention ratios, allowing for easy comparison of which communities maintain consistent user engagement over time.\n\n\nFindings\n\n\n\nUser Retention Heatmap\n\n\n\nNiche communities show sharp fluctuations. Subreddits like Alethics exhibit periods of extremely high retention (ratios near 1.0), suggesting that when relevant topics emerge, nearly all active users are returning participants. However, this engagement is event-driven and not sustained.\nMainstream AI subreddits maintain stable retention. Larger communities like ChatGPT, MachineLearning and OpenAI consistently show retention ratios in the 0.2–0.4 range. This stability reflects a healthier, more durable engagement structure with a continuous flow of content and a steady user base.\nGeneral AI forums demonstrate stronger cohesion. Communities like MachineLearning and OpenAI do not show extreme highs but maintain a persistent core of recurring users, indicating a well-established community identity that encourages return visits even without major events.\n\nIn summary, the heatmap highlights a clear distinction: niche subreddits achieve high short-term engagement but lack consistency, whereas mainstream subreddits sustain steady returning-user activity, suggesting stronger community health and long-term value."
  },
  {
    "objectID": "eda.html#business-question-3",
    "href": "eda.html#business-question-3",
    "title": "Exploratory Data Analysis",
    "section": "Business Question 3",
    "text": "Business Question 3\n\nHow concentrated is attention within AI and tech discussions?\n\n\nAnalysis Approach\nTo measure attention inequality, we calculated the Gini coefficient of comments per post for each subreddit. A Gini coefficient near 1 indicates that a very small number of “viral” posts attract most of the comments, while a value closer to 0 suggests that attention is distributed more evenly across many posts. We visualized these distributions using violin plots and bar charts to compare concentration levels.\n\n\nFindings\n\n\n\nDiscussion Gini Index Violin Plot\n\n\n\n\n\nAverage Gini Index Bar Chart\n\n\n\ntechnology and ChatGPT exhibit the highest attention concentration, with average Gini coefficients approaching 0.90. This “winner-take-most” dynamic is typical of large, news-driven communities where engagement is dominated by a few highly viral posts.\nTechnical communities show lower inequality. Subreddits like MachineLearning and datascience have more moderate Gini values (≈0.70–0.78). This indicates a healthier, more evenly distributed engagement pattern where discussions are spread across a wider range of specialized, topic-focused posts rather than a few viral threads.\nOpenAI occupies a middle ground, with moderate concentration levels but higher month-to-month variability, reflecting its sensitivity to event-driven news cycles.\n\nThese findings reveal a structural divide: general-interest subreddits are prone to viral, top-heavy discussions, while expert-focused communities foster a more equitable distribution of attention across multiple parallel conversations."
  },
  {
    "objectID": "eda.html#business-question-4",
    "href": "eda.html#business-question-4",
    "title": "Exploratory Data Analysis",
    "section": "Business Question 4",
    "text": "Business Question 4\n\nDo AI and technology subreddits share overlapping user communities?\n\n\nAnalysis Approach\nWe identified the unique user bases for each subreddit and then computed the pairwise Jaccard similarity to quantify the degree of user overlap between every pair of communities. The resulting similarity matrix was visualized as a heatmap, where warmer colors would indicate a higher percentage of shared users.\n\n\nFindings\n\n\n\nCross-Subreddit User Overlap Heatmap\n\n\n\nOverall user overlap is extremely low. The vast majority of Jaccard similarity scores are close to zero, indicating that the selected AI and technology subreddits attract largely distinct and separate audiences.\nEven closely related communities are siloed. For instance, AI-centric subreddits like ChatGPT, OpenAI, and ArtificialInteligence do not share a significant user base. This suggests that users tend to engage with platform- or topic-specific communities rather than participating broadly across the AI ecosystem.\nThe strong diagonal pattern in the heatmap visually confirms that each subreddit functions as a relatively independent community with minimal cross-pollination of users during the observed period."
  },
  {
    "objectID": "nlp.html#business-question-5",
    "href": "nlp.html#business-question-5",
    "title": "Natural Language Processing",
    "section": "Business Question 5",
    "text": "Business Question 5\n\nWhat are the dominant topics and trends within fast-growing technology-related subreddits?\n\nAs shown in the figure, the Latent Dirichlet Allocation (LDA) model identifies ten distinct topics from the corpus, each represented by its most influential keywords. These keywords provide an interpretable summary of the semantic focus of each discovered topic.\nTopic 0 is characterized by keywords such as data, apple, ai, science, user, and marketing, suggesting that this topic centers on discussions related to data science, artificial intelligence, and technology-driven business practices.\nTopic 1 includes terms such as karma, comment, subreddit, message, and questions, indicating that it reflects conversations about community interactions, platform moderation, and posting behaviors within online forums such as Reddit.\nTopic 2 is defined by words like human, ai, power, energy, car, and years, representing discourse around human–AI relations, emerging technologies, and long-term trends in energy and transportation.\nTopic 3 contains keywords including word, images, water, read, and data, pointing to content associated with information extraction, text and image processing, and data-driven analysis.\nTopic 4 focuses on terms such as code, python, data, using, language, and windows, clearly corresponding to programming-related discussions involving software tools, coding practices, and computational workflows.\nTopic 5 includes reddit, app, api, change, party, commercial, and pricing, which collectively suggest themes related to application development, API usage, and commercial product or platform changes.\nTopic 6 is composed of more conversational keywords such as something, never, someone, bad, lol, and yeah, indicating informal, colloquial exchanges or personal expressions within the corpus.\nTopic 7 features terms like learn, help, project, learning, software, and job, pointing to discussions focused on learning resources, technical support, project development, and career-oriented themes.\nTopic 8 is defined by job, jobs, entrepreneur, pay, business, and company, representing topics related to employment, entrepreneurship, compensation, and broader business activities.\nTopic 9 includes keywords such as chatgpt, bot, prompt, conversation, post, and reply, indicating discourse involving conversational agents, prompt design, and user–system interactions.\nOverall, these topics illustrate the LDA model’s ability to uncover coherent thematic structures within the dataset and to organize large volumes of text into interpretable clusters.\n\n\n\nTopic keywords\n\n\n\nOverall Topic Distribution\nAs shown in the pie chart, the Latent Dirichlet Allocation (LDA) model identifies ten distinct topics. Before ranking them, it is crucial to address Topic 6.\nA Note on Topic 6 (General Conversational Topic): Topic 6 (22.4%), with keywords like something, never, someone, bad, lol, yeah, represents a “background” or “general conversational” topic. It captures common, low-specificity words and conversational filler that are prevalent across the entire dataset but do not form a coherent semantic theme. The emergence of such a topic is a common and expected artifact of LDA. For the purpose of identifying the most significant thematic discussions, we will exclude Topic 6 from the subsequent ranking.\nAfter setting aside the general conversational topic, the most dominant thematic topics are as follows:\n\n\n\nOverall Topic Distribution\n\n\n\n1. Dominant Thematic Topics\n\nTopic 2 (13.6%)\nKeywords: human, ai, power, energy, car, years\nThis is the most prominent thematic topic, focusing on human–AI relations, emerging technologies, and long-term trends in energy and transportation. It highlights discussions centered on technological development and future-oriented themes.\nTopic 7 (13.0%)\nKeywords: learn, help, project, learning, software, job\nThis topic captures discourse around learning resources, technical support, project development, and career-related topics. It indicates active participation in educational and professional growth discussions within AI-focused communities.\nTopic 0 (11.8%)\nKeywords: data, apple, ai, science, user, marketing\nThis topic encompasses discussions at the intersection of technology and business, including data science, AI applications, and technology-driven business practices.\n\n\n\n2. Secondary Thematic Topics\n\nTopic 8 (11.3%)\nKeywords: job, jobs, entrepreneur, pay, business, company\nThis topic pertains to employment and entrepreneurship, reflecting user interest in career opportunities, compensation, and business activities.\nTopic 4 (11.0%)\nKeywords: code, python, data, using, language, windows\nThis topic represents programming and technical practice, emphasizing coding, software tools, and computational workflows.\n\n\n\n3. Peripheral Topics\n\nTopic 3 (7.7%)\nKeywords: word, images, water, read, data\nThis topic relates to information extraction, text and image processing, and data analysis.\nTopics 1, 5, 9 (&lt;5% each)\nThese topics include discussions about application development and APIs, community interactions, and conversational agents such as ChatGPT.\n\n\n\n4. Overall Interpretation\n\nAfter filtering out the large general conversational topic (Topic 6), the discourse is led by discussions on future-oriented technology and human-AI relations (Topic 2).\nCareer and learning-focused topics (Topics 7 and 8) remain highly significant, accounting for roughly 24% of the corpus and highlighting a strong user focus on professional development.\nTechnology and business-related discussions (Topics 0, 4) are also central, collectively representing over 22% of the content.\nThis revised distribution reveals that beneath a layer of casual conversation, the community’s core focus is on the future implications of technology, career growth, and practical applications in business and programming."
  },
  {
    "objectID": "nlp.html#business-question-6",
    "href": "nlp.html#business-question-6",
    "title": "Natural Language Processing",
    "section": "Business Question 6",
    "text": "Business Question 6\n\nWhat are the baseline emotional patterns of discussions about AI and emerging technologies?\n\nMethod: We applied the VADER sentiment analysis tool to each comment and submission to calculate a compound score, which ranges from -1 (most negative) to +1 (most positive). Scores are then categorized as positive (&gt;=0.05), neutral, or negative (&lt;=-0.05).\nAnalysis of Sentiment Distribution: The stacked bar chart below shows the proportion of comments falling into each sentiment category for the most active subreddits.\n\n\n\nSentiment distribution\n\n\n\nFinding 1: Neutrality is Dominant. Across almost all communities, the vast majority of comments are classified as neutral. This indicates that discussions on technical and scientific topics are often objective, informative, and factual rather than emotionally charged.\nFinding 2: Positive Skew. In most subreddits, the proportion of positive comments is noticeably higher than negative ones. This suggests a generally constructive or optimistic underlying tone, even within objective discussions.\n\nAnalysis of Average Compound Score: The bar chart below visualizes the average compound sentiment score for each subreddit.\n\n\n\ncompound\n\n\n\nFinding 3: Mildly Positive Atmosphere. Consistent with the distribution analysis, the average sentiment score for most subreddits is slightly above zero, confirming a modest but persistent positive inclination. For example, communities like AIforGood and OpenAI show a stronger positive leaning.\nFinding 4: Lack of Strong Negativity. Very few communities exhibit a negative average sentiment, and even those that do are only slightly negative. This reinforces the conclusion that the overall discussion atmosphere is not contentious but rather balanced and leaning towards positive."
  },
  {
    "objectID": "nlp.html#business-question-7",
    "href": "nlp.html#business-question-7",
    "title": "Natural Language Processing",
    "section": "Business Question 7",
    "text": "Business Question 7\n\nHow do external technological or policy events disrupt or reshape existing discussion patterns in online technology-related communities?\n\nWe selected a set of representative subreddits and categorized them into four major groups:\nAI/ML: This category includes ChatGPT, OpenAI, ArtificialIntelligence, MachineLearning, GenerativeAI, and AIethics. It focuses on discussions related to artificial intelligence, machine learning, generative AI, and associated ethical considerations.\nProgramming/Data: This group comprises datascience, bigdata, programming, Python, learnprogramming, and CloudComputing, highlighting topics in programming, data science, and technical learning.\nScience/STEM: Covering science, Physics, Engineering, Astronomy, Neuroscience, and MaterialsScience, this category addresses general science and STEM-related topics.\nTech/Future Trends: Including technology, Futurology, TechCulture, Innovation, and FutureTechnology, this category captures discussions about technological trends, innovation, and future-oriented topics.\nEach comment from these subreddits was analyzed using NLTK’s VADER to compute monthly average sentiment trends.\nIn the visualization, the vertical gray dashed lines represent key AI and technology events:\nClaude 2 launch (2023-07-12)\nOpenAI Developer Day (2023-11-06)\nGemini launch (2024-02-15)\nThe EU AI Act (2024-04-17)\nGPT-5 rumors (2024-06-20).\nThese lines serve as reference points to observe sentiment fluctuations around the time of significant events.\n\n\n\nSentiment trend\n\n\nAnalysis of Sentiment Trend: The chart below plots the average monthly sentiment for four distinct categories of subreddits. Key industry and policy events are marked with vertical lines to contextualize the trends.\n\n\n\nSentiment trend\n\n\n\nOverall Stability: The primary finding is that sentiment across all four categories remains remarkably stable over the year, with average scores consistently hovering in the neutral-to-mildly-positive range (0.05 to 0.15). This suggests a mature and steady discussion environment that is not prone to dramatic, long-term shifts in mood.\nEvent-Driven Fluctuations in AI/ML: The AI/ML category (blue line) displays the most sensitivity to external events.\n\nFollowing the Gemini launch (Feb 2024) and the EU AI Act (Apr 2024), this category shows a distinct upward trend, indicating a period of increased optimism and positive discussion.\nThis suggests that major product releases and significant regulatory milestones can temporarily boost positive sentiment within core AI communities.\n\nConsistency in Other Categories: The Programming/Data, Science/STEM, and Tech/Future Trends categories show even less volatility, reinforcing the idea that their discussion tones are less influenced by specific AI-related news cycles.\n\n\nTopic Trend\nWe also analyzed the distribution of the ten topics (discovered in RQ5) over time.\n\n\n\nTopic Trend\n\n\n\nConclusion: As shown in the stacked area chart, the relative prevalence of each topic remains highly consistent throughout the year. There are no major shifts, indicating that the fundamental areas of discussion within these communities are stable and not subject to seasonal or event-driven changes. For example, “informal conversation” (Topic 6) and “human-AI relations” (Topic 2) consistently remain the most dominant topics."
  },
  {
    "objectID": "nlp.html#business-question-8",
    "href": "nlp.html#business-question-8",
    "title": "Natural Language Processing",
    "section": "Business Question 8",
    "text": "Business Question 8\n\nHow do users shape topic emphasis and sentiment dynamics across science, technology, and AI subreddits?\n\nTo explore the semantic characteristics of discussions related to Technology, Science, and AI, word clouds were created to visualize the most frequent and prominent terms within each topic group.\nDiscussion content was classified into four categories using a rule-based approach:\n\nTechnical: Text containing keywords related to model architectures, neural networks, training, or optimization.\nEthical: Text containing keywords related to ethics, bias, regulations, or fairness.\nSocietal: Text containing keywords related to societal impact, education, policy, or employment.\nOther: Text not matching any of the above patterns.\n\nThis approach allows the word clouds to intuitively highlight the main topics and language features within each category, providing a visual understanding of community focus.\n\n\n\nWordCloud\n\n\nAnalysis: The word clouds reveal clear thematic distinctions between the different categories of discussion:\n\nEthical Discussion: Prominent keywords include regulation, responsibility, human, bias, fairness, and moral. This indicates that discourse in this category centers on the governance, accountability, and human-centric implications of AI and technology.\nSocietal Discussion: Dominant words include job, work, company, society, future, and impact. This highlights a focus on the real-world consequences of technology, particularly concerning employment, corporate influence, and long-term social structures.\nTechnical Discussion: Key terms are model, data, training, LLM, neural, and architecture. This demonstrates a clear focus on the mechanics of AI development, including model design, data handling, and the specifics of training large language models.\nOther Discussion: This category is characterized by general or meta-discussion words like removed, know, need, work, and time. It likely captures content related to moderation, general inquiries, or conversations that do not fit neatly into the other three themes."
  },
  {
    "objectID": "ml.html#business-question-9",
    "href": "ml.html#business-question-9",
    "title": "Machine Learning",
    "section": "Business Question 9",
    "text": "Business Question 9\n\nCan the Quality of Reddit Comments in Science, Technology, and AI Subreddits Be Predicted from comment content and basic behavioral features?\n\nThe Reddit score is calculated using the platform’s voting system and is defined as:\nscore = upvotes − downvotes\nThis value reflects community evaluation of how useful or high-quality a comment is.\nTo explore how well we can predict comment quality under different definitions, we designed three classification experiments:\n\nExperiment 1 – Predicting general high-quality comments\n\nPositive class: score ≥ 6\n\nRepresents comments with moderate positive engagement.\n\nExperiment 2 – Predicting highly popular high-quality comments\n\nPositive class: score ≥ 20\n\nTargets comments that achieved strong community resonance.\n\nExperiment 3 – Predicting low-quality comments\n\nPositive class: score &lt; 0\n\nA reverse-classification setup focusing on comments evaluated negatively by the community.\n\n\nClass weighting applied to address imbalance (weightCol used in LogisticRegression).\nTrain/test splits performed in code (80/20).\nAcross all three experiments, we trained Logistic Regression models using both TF-IDF text features and behavioral features such as comment length, URL presence, posting hour, and day of week.\nModel performance was evaluated using standard classification metrics including Accuracy, Precision, Recall, F1-score, and AUC.\n\nModel performance on Experiment 1\n\n\n\nMetric\nAccuracy\nPrecision\nRecall\nF1-score\nAUC\n\n\n\n\nValue\n0.5047\n0.2227\n0.7064\n0.3386\n0.6257\n\n\n\n\n  \n\nOverall, the model exhibits a clear bias in identifying high-quality comments. On one hand, it successfully detects 318,706 high-quality comments (true positives), demonstrating strong recall; on the other hand, it misclassifies 1,112,372 low-quality comments as high-quality (false positives), indicating substantial difficulty in distinguishing positive from negative samples. This “high recall, low precision” pattern means the model is effective at capturing potentially valuable content but generates a large number of false alarms, making it unsuitable for fully automated applications requiring high precision.\nIn terms of overall performance, the ROC curve shows AUC = 0.626, only slightly better than random guessing, indicating limited discriminative ability. Further inspection of the Precision–Recall curve reveals that, due to the low precision, simply adjusting thresholds is unlikely to significantly improve precision, reflecting a performance ceiling with the current feature representation. The main reason is that the current HashingTF text representation fails to effectively capture semantic information, making it difficult to distinguish high-value comments from regular ones.\n\n\nModel performance on Experiment 2\n\n\n\nMetric\nAccuracy\nPrecision\nRecall\nF1-score\nAUC\n\n\n\n\nLogisticRegression\n0.575\n0.069\n0.611\n0.125\n0.636\n\n\n\n\n  \n\nThe model identifies a portion of high-quality comments (76,072 true positives) but misclassifies a substantial number of low-quality comments as high-quality (1,020,158 false positives). In the original dataset, high-quality comments constitute only a small fraction of the total samples, reflecting a significant class imbalance. Although we applied class weighting in Logistic Regression to partially mitigate this imbalance, the model still exhibits extremely low precision (0.069) despite moderate recall (0.611).\nThe ROC curve shows AUC = 0.636, indicating that the model has modest discriminative ability — it performs better than random but is far from optimal. The Precision–Recall (PR) curve further highlights the issue: while recall is reasonable, precision remains extremely low, and adjusting the classification threshold is unlikely to improve it substantially. This demonstrates that the model tends to predict a large number of samples as positive (high-quality), resulting in many false positives.\n\n\nModel performance on Experiment 3\n\n\n\nAccuracy\nPrecision\nRecall\nF1-score\nAUC\n\n\n\n\n0.605\n0.067\n0.634\n0.121\n0.666\n\n\n\n\n  \n\nThe model identifies a portion of low-quality comments (68,049 true positives) but misclassifies a substantial number of high-quality comments as low-quality (953,913 false positives). In the original dataset, low-quality comments constitute only a small fraction of the total samples, reflecting a significant class imbalance. Although we applied class weighting in Logistic Regression to partially mitigate this imbalance, the model still exhibits extremely low precision (0.067) despite moderate recall (0.634).\nThe ROC curve shows AUC = 0.666, indicating that the model has modest discriminative ability — it performs better than random but is far from optimal. The Precision–Recall (PR) curve further highlights the issue: while recall is reasonable, precision remains extremely low, and adjusting the classification threshold is unlikely to improve it substantially. This demonstrates that the model tends to predict a large number of samples as positive (low-quality), resulting in many false positives.\nThis “high recall, very low precision” behavior suggests that the model may be useful for flagging potential low-quality comments for further review but is not suitable for fully automated high-precision applications. Compared with Experiment 1 (general high-quality comments), the precision is even lower, indicating that predicting low-quality comments is particularly challenging due to their rarity and the limitations of the current text and behavioral features.\nSummary and Comparison of Experiments:\nAcross the three experiments, Logistic Regression models showed the following patterns:\n\nExperiment 1 (general high-quality comments): High recall (≈71%) but low precision (≈22%), indicating the model can identify most high-quality comments but produces many false positives.\n\nExperiment 2 (highly popular high-quality comments): Even lower precision (≈7%) with moderate recall (≈63%), reflecting the difficulty of predicting rare highly popular comments despite applying class weighting.\n\nExperiment 3 (low-quality comments): Low precision (≈7%) with moderate recall (≈61%), showing that identifying low-quality comments is also challenging but feasible for flagging purposes.\n\nConclusion:\nLogistic Regression can partially predict comment quality using text and behavioral features. The models are useful for flagging candidate comments (high recall), but due to low precision, they are not suitable for fully automated decisions. Predicting extreme categories (highly popular or low-quality comments) is more difficult due to class imbalance and feature limitations.\nTherefore, key directions for improving model performance are:\n\nUse stronger semantic embeddings (e.g., BERT, Sentence-BERT) to better capture contextual and semantic information in comments.\nApply more powerful classifiers (e.g., Gradient Boosting, XGBoost, LightGBM) and incorporate richer metadata.\nFurther optimize threshold strategies and feature engineering based on task requirements."
  },
  {
    "objectID": "ml.html#business-question-10",
    "href": "ml.html#business-question-10",
    "title": "Machine Learning",
    "section": "Business Question 10",
    "text": "Business Question 10\n\nCan distinct discussion communities be identified within technology-related subreddits based on patterns of language use?\n\nIn this analysis, we aim to explore whether technology-related subreddits exhibit distinct discussion communities that can be characterized by their language patterns. By examining the textual content of subreddit submissions, we investigate the extent to which subreddits cluster together based on shared terminology, phrasing, and communication styles. Identifying these communities can provide insights into topic specialization, user engagement, and the structure of discourse across different forums. This understanding can also inform strategies for content moderation, recommendation systems, and targeted community engagement.\nWe randomly selected 50,000 subreddit submissions and applied K-Means clustering to their TF-IDF features. The goal was to identify groups of subreddits that share similar textual content and language use. The elbow method was used to determine the optimal number of clusters (K).\n\nCluster artifacts and model saved in code/ml/models/kmeans_k13.\nCluster analysis summary: data/csv/ML2_cluster_analysis.csv.\nElbow chart for K selection: data/plots/ML2_elbow_method.png.\n\n\nAfter applying the elbow method to evaluate the optimal number of clusters, and balancing within-cluster cohesion against between-cluster separation, we ultimately selected 13 clusters. This choice preserves thematic consistency within each cluster while ensuring sufficient distinction between clusters, thereby capturing meaningful differences in language use across technology-related subreddits.\nThis is the cluster visualization：\nThis cluster visualization shows that some clusters are fairly well-separated, while others are tightly overlapping. \nCluster Sizes and Distribution\nCluster sizes vary significantly, from small technical or code-specific clusters (size 6–185) to very large community discussion clusters (size 4,989–43,558).\nLargest clusters:\nCluster 10 (43,558) – AI community high-frequency discussions, including ChatGPT-related topics.\nCluster 8 (4,989) – Natural-language conversational discussions, reflecting informal user interactions.\nMedium clusters: Clusters 3, 6, and 11 (185–511) capture AI-related code/project discussions, AI comment interactions, and Python tutorials.\nSmall clusters: Clusters 0–5, 7, 9, 12 (6–301) are focused on specific programming tasks, code snippets, game logic, front-end layout, or grid/table operations.\n\n\n\n\n\n\n\n\n\nCluster ID\nSize\nTop Terms\nCategory Tendency\n\n\n\n\n0\n14\npaused, playing, def, import, printstrfplaypause, const, new, return, else\nAudio/video player related code snippets / scripting functionality\n\n\n1\n17\nreturn, x, resize, div, px, int, y, tilesize, public\nFront-end web layout / GUI related code\n\n\n2\n43\nreturn, import, def, guess, code, data, px, value, div\nPython programming basics / data processing / small program logic\n\n\n3\n185\nai, xb, code, import, new, data, x, return, use\nAI-related code or project implementation / algorithm development\n\n\n4\n13\nxb, false, player, temparray, return, gamepass, manufacturer, imgnull, true\nGame development or player logic / small program functionality\n\n\n5\n6\nreturn, import, public, int, new, cell, def, class, grid\nGrid or table processing / object-oriented basic code\n\n\n6\n511\nai, like, im, data, use, time, get, code, new\nAI community comments / user interaction related text\n\n\n7\n99\nimport, return, def, div, left, right, else, data, code\nFront-end layout and function logic / web page scripting\n\n\n8\n4989\nim, like, time, ive, know, get, work, ai, dont\nCommunity natural-language discussions / user comments / social interaction\n\n\n9\n162\ncode, import, xb, im, return, new, file, like, def\nProgramming discussion / file operations / small scripts\n\n\n10\n43558\nremoved, im, ai, like, chatgpt, gpt, new, use, get\nAI community high-frequency discussions / ChatGPT-related topics\n\n\n11\n301\ncode, im, def, xb, import, like, return, python, x\nProgramming tutorials / Python code examples / scripts\n\n\n12\n102\ntime, like, ai, xb, people, one, get, new, first\nAI community comments / user time and opinion expression\n\n\n\nCluster Content Summary\n\n\n\n\n\n\n\n\n\nCategory\nCluster IDs\nPercentage\nDescription\n\n\n\n\nNatural-Language / General Discussion\n10, 8, 6, 12\n98%\nLarge-scale conversational content, general discussions about AI, user opinions, and everyday language.\n\n\nProgramming / Technical Content\n0, 1, 2, 3, 5, 7, 9, 11\n2%\nCode snippets, debugging, Python scripts, front-end layouts, data-processing code, and AI project implementation.\n\n\n\nBased on K-Means clustering of 50,000 randomly selected subreddit submissions, we categorized 13 clusters into two main content domains: Natural-Language / General Discussion and Programming / Technical Content.\nNatural-Language / General Discussion (Clusters 6, 8, 10, 12 – 98% of submissions)\nCluster 10 (43,558 submissions): High-frequency AI discussions, including ChatGPT, AI concepts, and moderation-related content (‘removed’). Represents the largest portion of general AI conversations.\nCluster 8 (4,989 submissions): Conversational discussions with informal language (‘im’, ‘like’, ‘time’), reflecting community interactions and casual exchanges.\nCluster 6 (511 submissions): AI-related comments with a mix of technical terms and user interactions (‘ai’, ‘code’, ‘use’, ‘time’), bridging casual discussion and technical engagement.\nCluster 12 (102 submissions): Smaller cluster capturing user opinions, timing, and interaction patterns in AI-related discussions.\nInsight: These clusters dominate Reddit AI conversations, reflecting large-scale user engagement, opinion sharing, and general discussion.\nProgramming / Technical Content (Clusters 0, 1, 2, 3, 5, 7, 9, 11 – 2% of submissions)\nClusters 0, 1, 2, 5, 7, 9, 11: Focus on coding examples, debugging, front-end layouts, and small programming projects. Examples include Python basics, grid/table processing, and front-end scripts.\nCluster 3 (185 submissions): AI-related project implementation and algorithm development, combining technical code with problem-solving content.\nInsight: These clusters are smaller in size but highly specialized, capturing programming-focused discussions and technical knowledge sharing.\nThe clustering effectively separates high-volume conversational discussions from smaller, specialized technical content.\nLarge clusters (Natural-Language) reflect broad engagement and informal community interactions.\nSmall clusters (Technical Content) capture targeted programming topics and code-oriented tasks.\nThese cluster distinctions provide a foundation for feature engineering in predictive models, sentiment analysis, or engagement forecasting, allowing models to treat conversational and technical clusters differently."
  },
  {
    "objectID": "BUSINESS_QUESTIONS.html#question-10",
    "href": "BUSINESS_QUESTIONS.html#question-10",
    "title": "Project: Evolution of Online Science and Technology Communities on Reddit",
    "section": "",
    "text": "Can distinct discussion communities be identified within technology-related subreddits based on patterns of language use?\nAnalysis Type: ML Technical Approach (implemented): - Combine title and selftext to create document text, clean non-letter characters, and extract TF features using Tokenizer → StopWordsRemover → HashingTF → IDF (or CountVectorizer + IDF). - Use K-Means clustering (implementation includes elbow method to choose K), apply PCA for 2D visualization, and save cluster assignments and a cluster analysis (cluster sizes and top terms per cluster). Optionally compute sentiment per cluster for interpretation (TextBlob used in the script for simple sentiment aggregation). - Expected outcome: Identify distinct discussion directions, visualize cluster structure, and provide representative keywords per cluster."
  }
]